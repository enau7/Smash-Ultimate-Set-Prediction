{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_id</th>\n",
       "      <th>p2_id</th>\n",
       "      <th>p1_won</th>\n",
       "      <th>p1_games_played</th>\n",
       "      <th>p1_games_won</th>\n",
       "      <th>p2_games_played</th>\n",
       "      <th>p2_games_won</th>\n",
       "      <th>p1_char.-1</th>\n",
       "      <th>p1_char.banjokazooie</th>\n",
       "      <th>p1_char.bayonetta</th>\n",
       "      <th>...</th>\n",
       "      <th>stage.Town and City</th>\n",
       "      <th>stage.Unova Pokemon League</th>\n",
       "      <th>stage.Unova Pok√©mon League</th>\n",
       "      <th>stage.Venom</th>\n",
       "      <th>stage.WarioWare</th>\n",
       "      <th>stage.Wily Castle</th>\n",
       "      <th>stage.Yggdrasil's Altar</th>\n",
       "      <th>stage.Yoshi's Island</th>\n",
       "      <th>stage.Yoshi's Island (Melee)</th>\n",
       "      <th>stage.Yoshi's Story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1472816</td>\n",
       "      <td>1075251</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1075251</td>\n",
       "      <td>1472816</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>challonge__MrRiceman</td>\n",
       "      <td>challonge__Loconotcoco</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leo</td>\n",
       "      <td>1272809</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1034645</td>\n",
       "      <td>1302612</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963854</th>\n",
       "      <td>30896</td>\n",
       "      <td>4702</td>\n",
       "      <td>False</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>865</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963855</th>\n",
       "      <td>4702</td>\n",
       "      <td>30896</td>\n",
       "      <td>True</td>\n",
       "      <td>865</td>\n",
       "      <td>555</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963856</th>\n",
       "      <td>1263104</td>\n",
       "      <td>53481</td>\n",
       "      <td>True</td>\n",
       "      <td>186</td>\n",
       "      <td>112</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963857</th>\n",
       "      <td>53481</td>\n",
       "      <td>1263104</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>186</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963858</th>\n",
       "      <td>230918</td>\n",
       "      <td>30044</td>\n",
       "      <td>False</td>\n",
       "      <td>212</td>\n",
       "      <td>120</td>\n",
       "      <td>79</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963859 rows √ó 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        p1_id                   p2_id  p1_won  \\\n",
       "0                     1472816                 1075251   False   \n",
       "1                     1075251                 1472816    True   \n",
       "2        challonge__MrRiceman  challonge__Loconotcoco   False   \n",
       "3                         Leo                 1272809    True   \n",
       "4                     1034645                 1302612    True   \n",
       "...                       ...                     ...     ...   \n",
       "2963854                 30896                    4702   False   \n",
       "2963855                  4702                   30896    True   \n",
       "2963856               1263104                   53481    True   \n",
       "2963857                 53481                 1263104   False   \n",
       "2963858                230918                   30044   False   \n",
       "\n",
       "         p1_games_played  p1_games_won  p2_games_played  p2_games_won  \\\n",
       "0                      2             0               23            13   \n",
       "1                     23            13                2             0   \n",
       "2                      4             1                2             1   \n",
       "3                      1             1              102            49   \n",
       "4                     77            40                2             0   \n",
       "...                  ...           ...              ...           ...   \n",
       "2963854               72            51              865           555   \n",
       "2963855              865           555               72            51   \n",
       "2963856              186           112                8             7   \n",
       "2963857                8             7              186           112   \n",
       "2963858              212           120               79            53   \n",
       "\n",
       "         p1_char.-1  p1_char.banjokazooie  p1_char.bayonetta  ...  \\\n",
       "0                 0                     0                  0  ...   \n",
       "1                 0                     0                  0  ...   \n",
       "2                 0                     0                  0  ...   \n",
       "3                 0                     0                  0  ...   \n",
       "4                 0                     0                  0  ...   \n",
       "...             ...                   ...                ...  ...   \n",
       "2963854           0                     0                  0  ...   \n",
       "2963855           0                     0                  0  ...   \n",
       "2963856           0                     0                  0  ...   \n",
       "2963857           0                     0                  0  ...   \n",
       "2963858           0                     0                  0  ...   \n",
       "\n",
       "         stage.Town and City  stage.Unova Pokemon League  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "...                      ...                         ...   \n",
       "2963854                    0                           0   \n",
       "2963855                    0                           0   \n",
       "2963856                    0                           0   \n",
       "2963857                    0                           0   \n",
       "2963858                    0                           0   \n",
       "\n",
       "         stage.Unova Pok√©mon League  stage.Venom  stage.WarioWare  \\\n",
       "0                                 0            0                0   \n",
       "1                                 0            0                0   \n",
       "2                                 0            0                0   \n",
       "3                                 0            0                0   \n",
       "4                                 0            0                0   \n",
       "...                             ...          ...              ...   \n",
       "2963854                           0            0                0   \n",
       "2963855                           0            0                0   \n",
       "2963856                           0            0                0   \n",
       "2963857                           0            0                0   \n",
       "2963858                           0            0                0   \n",
       "\n",
       "         stage.Wily Castle  stage.Yggdrasil's Altar  stage.Yoshi's Island  \\\n",
       "0                        0                        0                     0   \n",
       "1                        0                        0                     0   \n",
       "2                        0                        0                     0   \n",
       "3                        0                        0                     0   \n",
       "4                        0                        0                     0   \n",
       "...                    ...                      ...                   ...   \n",
       "2963854                  0                        0                     0   \n",
       "2963855                  0                        0                     0   \n",
       "2963856                  0                        0                     0   \n",
       "2963857                  0                        0                     0   \n",
       "2963858                  0                        0                     0   \n",
       "\n",
       "         stage.Yoshi's Island (Melee)  stage.Yoshi's Story  \n",
       "0                                   0                    0  \n",
       "1                                   0                    0  \n",
       "2                                   0                    0  \n",
       "3                                   0                    0  \n",
       "4                                   0                    0  \n",
       "...                               ...                  ...  \n",
       "2963854                             0                    0  \n",
       "2963855                             0                    0  \n",
       "2963856                             0                    0  \n",
       "2963857                             0                    0  \n",
       "2963858                             0                    0  \n",
       "\n",
       "[2963859 rows x 237 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_data = pd.read_csv(\"../Data/data/clean_game_data.csv\",dtype={\"p1_id\" : \"string\",\"p2_id\" : \"string\",\"p1_char\" : \"string\", \"p2_char\" : \"string\", \"stage\" : \"string\", \"p1_games_played\" : \"int32\", \"p1_games_won\" : \"int32\", \"p2_games_played\" : \"int32\", \"p2_games_won\" : \"int32\", \"p1_won\" : \"bool\"})\n",
    "game_data = pd.get_dummies(game_data, columns=[\"p1_char\",\"p2_char\",\"stage\"], prefix_sep=\".\", )\n",
    "game_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `sklearn`, there aren't recipes. Instead, there are pipelines, which works a bit like a recipe and a workflow combined. We can apply transformations to our data including selecting predictors, normalizing variables, and adding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_train, game_test = train_test_split(game_data, train_size = 0.8, stratify = game_data[[\"p1_won\"]], random_state=2049)\n",
    "\n",
    "# We stratified on our response, p1_won. \n",
    "# This shouldn't make too much of a difference because we randomized which is p1 and p2, however it is still good practice.\n",
    "\n",
    "X = game_train.loc[:,game_train.columns != \"p1_won\"]\n",
    "y = game_train[\"p1_won\"]\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=5).split(X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by using our numerical predictors to fit a linear model. We want to use a logistic regression because we are predicting a binary class. We're going to score by accuracy because there is no class imbalance present (because we randomized p1_won) and accuracy is much easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x = [True, False], height = game_train[\"p1_won\"].value_counts() / len(game_train))\n",
    "plt.xticks([True, False], [\"True\", \"False\"])\n",
    "plt.title(\"p1_won True vs False\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitmodel(model, filename, df = game_train):\n",
    "    \n",
    "    if not os.path.isfile(filename):\n",
    "\n",
    "        model.fit(X,y)\n",
    "\n",
    "        joblib.dump(model, filename)\n",
    "\n",
    "    else:\n",
    "        modeltemp = joblib.load(filename)\n",
    "        if (type(model) != type(modeltemp)) or \\\n",
    "            (tuple([k[0] for k in model.steps]) != tuple([k[0] for k in modeltemp.steps])):\n",
    "            print (\"\\033[93m Warning: model mismatch. Delete the file {filename} and rerun or risk faulty models.\\n \\033[0m\".format(filename=filename))\n",
    "        model = modeltemp\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's fit a logistic regression with no penalty. For this and the elastic net, we'll just use the numerical predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6433 accuracy with a standard deviation of 0.0007.\n"
     ]
    }
   ],
   "source": [
    "lm_predictors = [\"p1_games_played\",\"p2_games_played\",\"p1_games_won\",\"p2_games_won\"]\n",
    "\n",
    "lm_pipe = Pipeline(steps = [\n",
    "    (\"predictors\", ColumnTransformer([(\"predictors\",\"passthrough\",lm_predictors)])),\n",
    "    (\"logistic\", linear_model.LogisticRegression(penalty=None))\n",
    "    ])\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=5).split(X,y)\n",
    "\n",
    "lm_cross_val = cross_val_score(estimator = lm_pipe,\n",
    "                               cv = game_folded,\n",
    "                               scoring = 'accuracy'\n",
    "                               X = X,\n",
    "                               y = y)\n",
    "\n",
    "print(\"%0.4f accuracy with a standard deviation of %0.4f.\" % (lm_cross_val.mean(), lm_cross_val.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = fitmodel(model = lm_pipe,\n",
    "              filename = \"models/logistic_regression.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to use an elastic net and tune the parameter `l1_ratio`, which gives the proportion of lasso regression to ridge regression. A value of `1.0` is expressed as a lasso regression, `0.0` is expressed as a ridge regression, and anything in between is some sort of elastic net. \n",
    "\n",
    "We can also tune C, a hyperparameter which controls penalty strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_predictors = [\"p1_games_played\",\"p2_games_played\",\"p1_games_won\",\"p2_games_won\"]\n",
    "\n",
    "en_pipe = Pipeline(steps = [\n",
    "    (\"predictors\", ColumnTransformer([(\"predictors\",\"passthrough\",en_predictors)])),\n",
    "    (\"logistic\", linear_model.LogisticRegression(solver='saga',penalty='elasticnet'))\n",
    "    ])\n",
    "\n",
    "en_grid = dict(logistic__l1_ratio = [0.0, 0.10, 0.25, 0.50, 0.75, 0.90, 1.0],\n",
    "               logistic__C = [1000, 100, 10, 1.0, 0.1, 0.01, 0.001])\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=5).split(X,y)\n",
    "\n",
    "en_grid_search = GridSearchCV(estimator = en_pipe,\n",
    "                            param_grid = en_grid,\n",
    "                            n_jobs = 1,\n",
    "                            cv = game_folded,\n",
    "                            scoring = 'accuracy',\n",
    "                            error_score = 0,\n",
    "                            verbose = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "[CV 1/5] END logistic__C=1000, logistic__l1_ratio=0.0;, score=0.679 total time=   7.2s\n",
      "[CV 2/5] END logistic__C=1000, logistic__l1_ratio=0.0;, score=0.679 total time=   7.2s\n",
      "[CV 3/5] END logistic__C=1000, logistic__l1_ratio=0.0;, score=0.679 total time=   7.1s\n",
      "[CV 4/5] END logistic__C=1000, logistic__l1_ratio=0.0;, score=0.681 total time=   7.7s\n",
      "[CV 5/5] END logistic__C=1000, logistic__l1_ratio=0.0;, score=0.680 total time=   7.0s\n",
      "[CV 1/5] END logistic__C=1000, logistic__l1_ratio=0.1;, score=0.679 total time=   7.2s\n",
      "[CV 2/5] END logistic__C=1000, logistic__l1_ratio=0.1;, score=0.679 total time=   7.3s\n",
      "[CV 3/5] END logistic__C=1000, logistic__l1_ratio=0.1;, score=0.679 total time=   7.2s\n",
      "[CV 4/5] END logistic__C=1000, logistic__l1_ratio=0.1;, score=0.681 total time=   7.3s\n",
      "[CV 5/5] END logistic__C=1000, logistic__l1_ratio=0.1;, score=0.680 total time=   7.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m en_grid_result \u001b[39m=\u001b[39m en_grid_search\u001b[39m.\u001b[39;49mfit(X[en_predictors],y) \u001b[39m# We pass in X[en_predictors] because the result is the same but slightly faster.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1289\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1291\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[0;32m   1292\u001b[0m     path_func(\n\u001b[0;32m   1293\u001b[0m         X,\n\u001b[0;32m   1294\u001b[0m         y,\n\u001b[0;32m   1295\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[0;32m   1296\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1297\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1298\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1299\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1300\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1301\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1302\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[0;32m   1303\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1304\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m   1305\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1306\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1307\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1308\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[0;32m   1309\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1310\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1311\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[0;32m   1312\u001b[0m     )\n\u001b[0;32m   1313\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[0;32m   1314\u001b[0m )\n\u001b[0;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:524\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    521\u001b[0m         alpha \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m l1_ratio)\n\u001b[0;32m    522\u001b[0m         beta \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m l1_ratio\n\u001b[1;32m--> 524\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[39m=\u001b[39m sag_solver(\n\u001b[0;32m    525\u001b[0m         X,\n\u001b[0;32m    526\u001b[0m         target,\n\u001b[0;32m    527\u001b[0m         sample_weight,\n\u001b[0;32m    528\u001b[0m         loss,\n\u001b[0;32m    529\u001b[0m         alpha,\n\u001b[0;32m    530\u001b[0m         beta,\n\u001b[0;32m    531\u001b[0m         max_iter,\n\u001b[0;32m    532\u001b[0m         tol,\n\u001b[0;32m    533\u001b[0m         verbose,\n\u001b[0;32m    534\u001b[0m         random_state,\n\u001b[0;32m    535\u001b[0m         \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    536\u001b[0m         max_squared_sum,\n\u001b[0;32m    537\u001b[0m         warm_start_sag,\n\u001b[0;32m    538\u001b[0m         is_saga\u001b[39m=\u001b[39;49m(solver \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    539\u001b[0m     )\n\u001b[0;32m    541\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    543\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msolver must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m solver\n\u001b[0;32m    545\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:325\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent sag implementation does not handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    324\u001b[0m sag \u001b[39m=\u001b[39m sag64 \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64 \u001b[39melse\u001b[39;00m sag32\n\u001b[1;32m--> 325\u001b[0m num_seen, n_iter_ \u001b[39m=\u001b[39m sag(\n\u001b[0;32m    326\u001b[0m     dataset,\n\u001b[0;32m    327\u001b[0m     coef_init,\n\u001b[0;32m    328\u001b[0m     intercept_init,\n\u001b[0;32m    329\u001b[0m     n_samples,\n\u001b[0;32m    330\u001b[0m     n_features,\n\u001b[0;32m    331\u001b[0m     n_classes,\n\u001b[0;32m    332\u001b[0m     tol,\n\u001b[0;32m    333\u001b[0m     max_iter,\n\u001b[0;32m    334\u001b[0m     loss,\n\u001b[0;32m    335\u001b[0m     step_size,\n\u001b[0;32m    336\u001b[0m     alpha_scaled,\n\u001b[0;32m    337\u001b[0m     beta_scaled,\n\u001b[0;32m    338\u001b[0m     sum_gradient_init,\n\u001b[0;32m    339\u001b[0m     gradient_memory_init,\n\u001b[0;32m    340\u001b[0m     seen_init,\n\u001b[0;32m    341\u001b[0m     num_seen_init,\n\u001b[0;32m    342\u001b[0m     fit_intercept,\n\u001b[0;32m    343\u001b[0m     intercept_sum_gradient,\n\u001b[0;32m    344\u001b[0m     intercept_decay,\n\u001b[0;32m    345\u001b[0m     is_saga,\n\u001b[0;32m    346\u001b[0m     verbose,\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    349\u001b[0m \u001b[39mif\u001b[39;00m n_iter_ \u001b[39m==\u001b[39m max_iter:\n\u001b[0;32m    350\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    351\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    352\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    353\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "en_grid_result = en_grid_search.fit(X[en_predictors],y) # We pass in X[en_predictors] because the result is the same but slightly faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01, l1_ratio = 1.0, with an accuracy of 0.6431155838173498.\n",
      "\n",
      "   param_logistic__l1_ratio param_logistic__C  mean_test_score\n",
      "0                       0.0              1000         0.643111\n",
      "1                       0.1              1000         0.643091\n",
      "2                      0.25              1000         0.643102\n",
      "3                       0.5              1000         0.643092\n",
      "4                      0.75              1000         0.643100\n",
      "5                       0.9              1000         0.643089\n",
      "6                       1.0              1000         0.643097\n",
      "7                       0.0               100         0.643077\n",
      "8                       0.1               100         0.643110\n",
      "9                      0.25               100         0.643108\n",
      "10                      0.5               100         0.643092\n",
      "11                     0.75               100         0.643105\n",
      "12                      0.9               100         0.643094\n",
      "13                      1.0               100         0.643107\n",
      "14                      0.0                10         0.643084\n",
      "15                      0.1                10         0.643113\n",
      "16                     0.25                10         0.643109\n",
      "17                      0.5                10         0.643092\n",
      "18                     0.75                10         0.643090\n",
      "19                      0.9                10         0.643100\n",
      "20                      1.0                10         0.643104\n",
      "21                      0.0               1.0         0.643085\n",
      "22                      0.1               1.0         0.643099\n",
      "23                     0.25               1.0         0.643100\n",
      "24                      0.5               1.0         0.643093\n",
      "25                     0.75               1.0         0.643107\n",
      "26                      0.9               1.0         0.643094\n",
      "27                      1.0               1.0         0.643114\n",
      "28                      0.0               0.1         0.643106\n",
      "29                      0.1               0.1         0.643093\n",
      "30                     0.25               0.1         0.643096\n",
      "31                      0.5               0.1         0.643099\n",
      "32                     0.75               0.1         0.643105\n",
      "33                      0.9               0.1         0.643113\n",
      "34                      1.0               0.1         0.643092\n",
      "35                      0.0              0.01         0.643079\n",
      "36                      0.1              0.01         0.643081\n",
      "37                     0.25              0.01         0.643097\n",
      "38                      0.5              0.01         0.643086\n",
      "39                     0.75              0.01         0.643089\n",
      "40                      0.9              0.01         0.643105\n",
      "41                      1.0              0.01         0.643116\n",
      "42                      0.0             0.001         0.643110\n",
      "43                      0.1             0.001         0.643100\n",
      "44                     0.25             0.001         0.643102\n",
      "45                      0.5             0.001         0.643094\n",
      "46                     0.75             0.001         0.643106\n",
      "47                      0.9             0.001         0.643100\n",
      "48                      1.0             0.001         0.643099\n"
     ]
    }
   ],
   "source": [
    "print(\"C = {bestC}, l1_ratio = {bestratio}, with an accuracy of {bestScore}.\\n\".format(\n",
    "    bestC = en_grid_result.best_params_['logistic__C'],\n",
    "    bestratio = en_grid_result.best_params_['logistic__l1_ratio'],\n",
    "    bestScore = en_grid_result.best_score_))\n",
    "\n",
    "res = pd.DataFrame(en_grid_result.cv_results_)\n",
    "print(res[['param_logistic__l1_ratio','param_logistic__C','mean_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pipe.set_params(logistic__C = 0.01, logistic__l1_ratio = 1.0)\n",
    "en = fitmodel(model = en_pipe,\n",
    "              filename = \"models/elastic_net.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to keep in mind is that games played and games won are relative to the size of the dataset, so it might be a good idea to use a proportion between players instead in case someone wants to use the final model on a dataset which is not of the same size. It's unclear if this will matter though.\n",
    "\n",
    "The goal of this project is more interpretation/inference than predicition, so we can hold this thought for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictors = list(set(game_train.head()).difference({\"p1_won\",\"p1_id\",\"p2_id\"}))\n",
    "\n",
    "dtc_pipe = Pipeline(steps = [\n",
    "    (\"predictors\", ColumnTransformer([(\"predictors\",\"passthrough\",dtc_predictors)])),\n",
    "    (\"decision_tree\", tree.DecisionTreeClassifier(random_state = 42))\n",
    "    ])\n",
    "\n",
    "dtc_grid = dict(decision_tree__ccp_alpha = [0.000, 0.005, 0.010, 0.020],\n",
    "                decision_tree__max_depth = [3, 5, 10, None],\n",
    "                decision_tree__min_samples_leaf = [1, 3, 5, 10])\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=5).split(X,y)\n",
    "\n",
    "dtc_grid_search = GridSearchCV(estimator = dtc_pipe,\n",
    "                               param_grid = dtc_grid,\n",
    "                               n_jobs = 4,\n",
    "                               cv = game_folded,\n",
    "                               scoring = 'accuracy',\n",
    "                               error_score = 0,\n",
    "                               verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dtc_grid_result \u001b[39m=\u001b[39m dtc_grid_search\u001b[39m.\u001b[39;49mfit(X[dtc_predictors],y)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 440\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtc_grid_result = dtc_grid_search.fit(X[dtc_predictors],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Features = None, Max Depth = 10, Min Samples Leaf = 10, with an accuracy of 0.646869980057419.\n",
      "\n",
      "   param_decision_tree__max_features param_decision_tree__max_depth  \\\n",
      "0                               sqrt                              3   \n",
      "1                               sqrt                              3   \n",
      "2                               sqrt                              3   \n",
      "3                               sqrt                              3   \n",
      "4                               log2                              3   \n",
      "5                               log2                              3   \n",
      "6                               log2                              3   \n",
      "7                               log2                              3   \n",
      "8                               None                              3   \n",
      "9                               None                              3   \n",
      "10                              None                              3   \n",
      "11                              None                              3   \n",
      "12                              sqrt                              5   \n",
      "13                              sqrt                              5   \n",
      "14                              sqrt                              5   \n",
      "15                              sqrt                              5   \n",
      "16                              log2                              5   \n",
      "17                              log2                              5   \n",
      "18                              log2                              5   \n",
      "19                              log2                              5   \n",
      "20                              None                              5   \n",
      "21                              None                              5   \n",
      "22                              None                              5   \n",
      "23                              None                              5   \n",
      "24                              sqrt                             10   \n",
      "25                              sqrt                             10   \n",
      "26                              sqrt                             10   \n",
      "27                              sqrt                             10   \n",
      "28                              log2                             10   \n",
      "29                              log2                             10   \n",
      "30                              log2                             10   \n",
      "31                              log2                             10   \n",
      "32                              None                             10   \n",
      "33                              None                             10   \n",
      "34                              None                             10   \n",
      "35                              None                             10   \n",
      "36                              sqrt                           None   \n",
      "37                              sqrt                           None   \n",
      "38                              sqrt                           None   \n",
      "39                              sqrt                           None   \n",
      "40                              log2                           None   \n",
      "41                              log2                           None   \n",
      "42                              log2                           None   \n",
      "43                              log2                           None   \n",
      "44                              None                           None   \n",
      "45                              None                           None   \n",
      "46                              None                           None   \n",
      "47                              None                           None   \n",
      "\n",
      "   param_decision_tree__min_samples_leaf  mean_test_score  \n",
      "0                                      1         0.573248  \n",
      "1                                      3         0.573248  \n",
      "2                                      5         0.573248  \n",
      "3                                     10         0.573248  \n",
      "4                                      1         0.503296  \n",
      "5                                      3         0.503296  \n",
      "6                                      5         0.503296  \n",
      "7                                     10         0.503296  \n",
      "8                                      1         0.621485  \n",
      "9                                      3         0.621485  \n",
      "10                                     5         0.621485  \n",
      "11                                    10         0.621485  \n",
      "12                                     1         0.583330  \n",
      "13                                     3         0.583329  \n",
      "14                                     5         0.583330  \n",
      "15                                    10         0.583330  \n",
      "16                                     1         0.506678  \n",
      "17                                     3         0.506671  \n",
      "18                                     5         0.506672  \n",
      "19                                    10         0.506671  \n",
      "20                                     1         0.631875  \n",
      "21                                     3         0.631875  \n",
      "22                                     5         0.631875  \n",
      "23                                    10         0.631875  \n",
      "24                                     1         0.601990  \n",
      "25                                     3         0.602716  \n",
      "26                                     5         0.607654  \n",
      "27                                    10         0.594804  \n",
      "28                                     1         0.512148  \n",
      "29                                     3         0.512231  \n",
      "30                                     5         0.512486  \n",
      "31                                    10         0.512306  \n",
      "32                                     1         0.646803  \n",
      "33                                     3         0.646792  \n",
      "34                                     5         0.646820  \n",
      "35                                    10         0.646870  \n",
      "36                                     1         0.597343  \n",
      "37                                     3         0.626045  \n",
      "38                                     5         0.634018  \n",
      "39                                    10         0.639746  \n",
      "40                                     1         0.580045  \n",
      "41                                     3         0.614233  \n",
      "42                                     5         0.617712  \n",
      "43                                    10         0.617297  \n",
      "44                                     1         0.616649  \n",
      "45                                     3         0.615557  \n",
      "46                                     5         0.622533  \n",
      "47                                    10         0.636903  \n"
     ]
    }
   ],
   "source": [
    "print(\"Max Features = {bestccp}, Max Depth = {bestMD}, Min Samples Leaf = {bestMS}, with an accuracy of {bestScore}.\\n\".format(\n",
    "    bestccp = dtc_grid_result.best_params_['decision_tree__ccp_alpha'],\n",
    "    bestMD = dtc_grid_result.best_params_['decision_tree__max_depth'],\n",
    "    bestMS = dtc_grid_result.best_params_['decision_tree__min_samples_leaf'],\n",
    "    bestScore = dtc_grid_result.best_score_))\n",
    "\n",
    "res = pd.DataFrame(dtc_grid_result.cv_results_)\n",
    "print(res[['param_decision_tree__max_features',\n",
    "           'param_decision_tree__max_depth',\n",
    "           'param_decision_tree__min_samples_leaf',\n",
    "           'mean_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pipe.set_params(decision_tree__max_features = None, decision_tree__max_depth = 10, decision_tree__min_samples_leaf = 10)\n",
    "\n",
    "dtc = fitmodel(model = dtc_pipe,\n",
    "               filename = \"models/decision_tree.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predictors = list(set(game_train.head()).difference({\"p1_won\",\"p1_id\",\"p2_id\"}))\n",
    "\n",
    "rfc_pipe = Pipeline(steps = [\n",
    "            (\"predictors\", ColumnTransformer([(\"predictors\",\"passthrough\",rfc_predictors)])),\n",
    "            (\"random_forest\", ensemble.RandomForestClassifier(verbose = 3, n_jobs = 4, random_state = 420))\n",
    "            ])\n",
    "\n",
    "rfc_grid = dict(random_forest__n_estimators = [100,200,400],\n",
    "                random_forest__min_samples_leaf = [1, 3, 5, 10])\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=2).split(X,y) # 5 folds takes a LONG time to run...\n",
    "\n",
    "rfc_grid_search = GridSearchCV(estimator = rfc_pipe,\n",
    "                               param_grid = rfc_grid,\n",
    "                               n_jobs = 1,\n",
    "                               cv = game_folded,\n",
    "                               scoring = 'accuracy',\n",
    "                               error_score = 0,\n",
    "                               verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "[CV 1/2; 1/12] START random_forest__min_samples_leaf=1, random_forest__n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   21.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 1/12] END random_forest__min_samples_leaf=1, random_forest__n_estimators=100;, score=0.664 total time= 5.0min\n",
      "[CV 2/2; 1/12] START random_forest__min_samples_leaf=1, random_forest__n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  4.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   21.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 1/12] END random_forest__min_samples_leaf=1, random_forest__n_estimators=100;, score=0.665 total time= 4.6min\n",
      "[CV 1/2; 2/12] START random_forest__min_samples_leaf=1, random_forest__n_estimators=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  8.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   50.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 2/12] END random_forest__min_samples_leaf=1, random_forest__n_estimators=200;, score=0.666 total time= 9.5min\n",
      "[CV 2/2; 2/12] START random_forest__min_samples_leaf=1, random_forest__n_estimators=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  8.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   49.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 2/12] END random_forest__min_samples_leaf=1, random_forest__n_estimators=200;, score=0.667 total time= 9.4min\n",
      "[CV 1/2; 3/12] START random_forest__min_samples_leaf=1, random_forest__n_estimators=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   58.7s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed: 16.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 3/12] END random_forest__min_samples_leaf=1, random_forest__n_estimators=400;, score=0.667 total time=18.6min\n",
      "[CV 2/2; 3/12] START random_forest__min_samples_leaf=1, random_forest__n_estimators=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed: 17.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 3/12] END random_forest__min_samples_leaf=1, random_forest__n_estimators=400;, score=0.668 total time=19.7min\n",
      "[CV 1/2; 4/12] START random_forest__min_samples_leaf=3, random_forest__n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 4/12] END random_forest__min_samples_leaf=3, random_forest__n_estimators=100;, score=0.672 total time= 4.0min\n",
      "[CV 2/2; 4/12] START random_forest__min_samples_leaf=3, random_forest__n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 4/12] END random_forest__min_samples_leaf=3, random_forest__n_estimators=100;, score=0.672 total time= 4.0min\n",
      "[CV 1/2; 5/12] START random_forest__min_samples_leaf=3, random_forest__n_estimators=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  7.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   23.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 5/12] END random_forest__min_samples_leaf=3, random_forest__n_estimators=200;, score=0.672 total time= 7.9min\n",
      "[CV 2/2; 5/12] START random_forest__min_samples_leaf=3, random_forest__n_estimators=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  7.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   23.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 5/12] END random_forest__min_samples_leaf=3, random_forest__n_estimators=200;, score=0.673 total time= 7.8min\n",
      "[CV 1/2; 6/12] START random_forest__min_samples_leaf=3, random_forest__n_estimators=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed: 14.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   47.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 6/12] END random_forest__min_samples_leaf=3, random_forest__n_estimators=400;, score=0.672 total time=15.6min\n",
      "[CV 2/2; 6/12] START random_forest__min_samples_leaf=3, random_forest__n_estimators=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed: 14.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   48.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 6/12] END random_forest__min_samples_leaf=3, random_forest__n_estimators=400;, score=0.674 total time=15.6min\n",
      "[CV 1/2; 7/12] START random_forest__min_samples_leaf=5, random_forest__n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   10.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 7/12] END random_forest__min_samples_leaf=5, random_forest__n_estimators=100;, score=0.670 total time= 3.8min\n",
      "[CV 2/2; 7/12] START random_forest__min_samples_leaf=5, random_forest__n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   10.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 7/12] END random_forest__min_samples_leaf=5, random_forest__n_estimators=100;, score=0.671 total time= 3.8min\n",
      "[CV 1/2; 8/12] START random_forest__min_samples_leaf=5, random_forest__n_estimators=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  7.0min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 8/12] END random_forest__min_samples_leaf=5, random_forest__n_estimators=200;, score=0.670 total time= 7.4min\n",
      "[CV 2/2; 8/12] START random_forest__min_samples_leaf=5, random_forest__n_estimators=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  7.0min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   20.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 8/12] END random_forest__min_samples_leaf=5, random_forest__n_estimators=200;, score=0.671 total time= 7.4min\n",
      "[CV 1/2; 9/12] START random_forest__min_samples_leaf=5, random_forest__n_estimators=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed: 14.0min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   40.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 9/12] END random_forest__min_samples_leaf=5, random_forest__n_estimators=400;, score=0.670 total time=14.8min\n",
      "[CV 2/2; 9/12] START random_forest__min_samples_leaf=5, random_forest__n_estimators=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed: 14.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   38.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 9/12] END random_forest__min_samples_leaf=5, random_forest__n_estimators=400;, score=0.672 total time=15.1min\n",
      "[CV 1/2; 10/12] START random_forest__min_samples_leaf=10, random_forest__n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 10/12] END random_forest__min_samples_leaf=10, random_forest__n_estimators=100;, score=0.666 total time= 3.5min\n",
      "[CV 2/2; 10/12] START random_forest__min_samples_leaf=10, random_forest__n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 10/12] END random_forest__min_samples_leaf=10, random_forest__n_estimators=100;, score=0.667 total time= 3.6min\n",
      "[CV 1/2; 11/12] START random_forest__min_samples_leaf=10, random_forest__n_estimators=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  6.8min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   18.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 11/12] END random_forest__min_samples_leaf=10, random_forest__n_estimators=200;, score=0.666 total time= 7.2min\n",
      "[CV 2/2; 11/12] START random_forest__min_samples_leaf=10, random_forest__n_estimators=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  6.8min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   18.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 11/12] END random_forest__min_samples_leaf=10, random_forest__n_estimators=200;, score=0.668 total time= 7.2min\n",
      "[CV 1/2; 12/12] START random_forest__min_samples_leaf=10, random_forest__n_estimators=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed: 13.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   35.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 12/12] END random_forest__min_samples_leaf=10, random_forest__n_estimators=400;, score=0.667 total time=13.8min\n",
      "[CV 2/2; 12/12] START random_forest__min_samples_leaf=10, random_forest__n_estimators=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed: 13.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   36.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 12/12] END random_forest__min_samples_leaf=10, random_forest__n_estimators=400;, score=0.668 total time=13.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 400building tree 1 of 400\n",
      "building tree 3 of 400\n",
      "building tree 4 of 400\n",
      "\n",
      "building tree 5 of 400\n",
      "building tree 6 of 400\n",
      "building tree 7 of 400\n",
      "building tree 8 of 400\n",
      "building tree 9 of 400\n",
      "building tree 10 of 400\n",
      "building tree 11 of 400\n",
      "building tree 12 of 400\n",
      "building tree 13 of 400\n",
      "building tree 14 of 400\n",
      "building tree 15 of 400\n",
      "building tree 16 of 400\n",
      "building tree 17 of 400\n",
      "building tree 18 of 400\n",
      "building tree 19 of 400\n",
      "building tree 20 of 400\n",
      "building tree 21 of 400\n",
      "building tree 22 of 400\n",
      "building tree 23 of 400\n",
      "building tree 24 of 400\n",
      "building tree 25 of 400\n",
      "building tree 26 of 400\n",
      "building tree 27 of 400\n",
      "building tree 28 of 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  2.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 29 of 400\n",
      "building tree 30 of 400\n",
      "building tree 31 of 400\n",
      "building tree 32 of 400\n",
      "building tree 33 of 400\n",
      "building tree 34 of 400\n",
      "building tree 35 of 400\n",
      "building tree 36 of 400\n",
      "building tree 37 of 400\n",
      "building tree 38 of 400\n",
      "building tree 39 of 400\n",
      "building tree 40 of 400\n",
      "building tree 41 of 400\n",
      "building tree 42 of 400\n",
      "building tree 43 of 400\n",
      "building tree 44 of 400\n",
      "building tree 45 of 400\n",
      "building tree 46 of 400\n",
      "building tree 47 of 400\n",
      "building tree 48 of 400\n",
      "building tree 49 of 400\n",
      "building tree 50 of 400\n",
      "building tree 51 of 400\n",
      "building tree 52 of 400\n",
      "building tree 53 of 400\n",
      "building tree 54 of 400\n",
      "building tree 55 of 400\n",
      "building tree 56 of 400\n",
      "building tree 57 of 400\n",
      "building tree 58 of 400\n",
      "building tree 59 of 400\n",
      "building tree 60 of 400\n",
      "building tree 61 of 400\n",
      "building tree 62 of 400\n",
      "building tree 63 of 400\n",
      "building tree 64 of 400\n",
      "building tree 65 of 400\n",
      "building tree 66 of 400\n",
      "building tree 67 of 400\n",
      "building tree 68 of 400\n",
      "building tree 69 of 400\n",
      "building tree 70 of 400\n",
      "building tree 71 of 400\n",
      "building tree 72 of 400\n",
      "building tree 73 of 400\n",
      "building tree 74 of 400\n",
      "building tree 75 of 400\n",
      "building tree 76 of 400\n",
      "building tree 77 of 400\n",
      "building tree 78 of 400\n",
      "building tree 79 of 400\n",
      "building tree 80 of 400\n",
      "building tree 81 of 400\n",
      "building tree 82 of 400\n",
      "building tree 83 of 400\n",
      "building tree 84 of 400\n",
      "building tree 85 of 400\n",
      "building tree 86 of 400\n",
      "building tree 87 of 400\n",
      "building tree 88 of 400\n",
      "building tree 89 of 400\n",
      "building tree 90 of 400\n",
      "building tree 91 of 400\n",
      "building tree 92 of 400\n",
      "building tree 93 of 400\n",
      "building tree 94 of 400\n",
      "building tree 95 of 400\n",
      "building tree 96 of 400\n",
      "building tree 97 of 400\n",
      "building tree 98 of 400\n",
      "building tree 99 of 400\n",
      "building tree 100 of 400\n",
      "building tree 101 of 400\n",
      "building tree 102 of 400\n",
      "building tree 103 of 400\n",
      "building tree 104 of 400\n",
      "building tree 105 of 400\n",
      "building tree 106 of 400\n",
      "building tree 107 of 400\n",
      "building tree 108 of 400\n",
      "building tree 109 of 400\n",
      "building tree 110 of 400\n",
      "building tree 111 of 400\n",
      "building tree 112 of 400\n",
      "building tree 113 of 400\n",
      "building tree 114 of 400\n",
      "building tree 115 of 400\n",
      "building tree 116 of 400\n",
      "building tree 117 of 400\n",
      "building tree 118 of 400\n",
      "building tree 119 of 400\n",
      "building tree 120 of 400\n",
      "building tree 121 of 400\n",
      "building tree 122 of 400\n",
      "building tree 123 of 400\n",
      "building tree 124 of 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 10.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 125 of 400\n",
      "building tree 126 of 400\n",
      "building tree 127 of 400\n",
      "building tree 128 of 400\n",
      "building tree 129 of 400\n",
      "building tree 130 of 400\n",
      "building tree 131 of 400\n",
      "building tree 132 of 400\n",
      "building tree 133 of 400\n",
      "building tree 134 of 400\n",
      "building tree 135 of 400\n",
      "building tree 136 of 400\n",
      "building tree 137 of 400\n",
      "building tree 138 of 400\n",
      "building tree 139 of 400\n",
      "building tree 140 of 400\n",
      "building tree 141 of 400\n",
      "building tree 142 of 400\n",
      "building tree 143 of 400\n",
      "building tree 144 of 400\n",
      "building tree 145 of 400\n",
      "building tree 146 of 400\n",
      "building tree 147 of 400\n",
      "building tree 148 of 400\n",
      "building tree 149 of 400\n",
      "building tree 150 of 400\n",
      "building tree 151 of 400\n",
      "building tree 152 of 400\n",
      "building tree 153 of 400\n",
      "building tree 154 of 400\n",
      "building tree 155 of 400\n",
      "building tree 156 of 400\n",
      "building tree 157 of 400\n",
      "building tree 158 of 400\n",
      "building tree 159 of 400\n",
      "building tree 160 of 400\n",
      "building tree 161 of 400\n",
      "building tree 162 of 400\n",
      "building tree 163 of 400\n",
      "building tree 164 of 400\n",
      "building tree 165 of 400\n",
      "building tree 166 of 400\n",
      "building tree 167 of 400\n",
      "building tree 168 of 400\n",
      "building tree 169 of 400\n",
      "building tree 170 of 400\n",
      "building tree 171 of 400\n",
      "building tree 172 of 400\n",
      "building tree 173 of 400\n",
      "building tree 174 of 400\n",
      "building tree 175 of 400\n",
      "building tree 176 of 400\n",
      "building tree 177 of 400\n",
      "building tree 178 of 400\n",
      "building tree 179 of 400\n",
      "building tree 180 of 400\n",
      "building tree 181 of 400\n",
      "building tree 182 of 400\n",
      "building tree 183 of 400\n",
      "building tree 184 of 400\n",
      "building tree 185 of 400\n",
      "building tree 186 of 400\n",
      "building tree 187 of 400\n",
      "building tree 188 of 400\n",
      "building tree 189 of 400\n",
      "building tree 190 of 400\n",
      "building tree 191 of 400\n",
      "building tree 192 of 400\n",
      "building tree 193 of 400\n",
      "building tree 194 of 400\n",
      "building tree 195 of 400\n",
      "building tree 196 of 400\n",
      "building tree 197 of 400\n",
      "building tree 198 of 400\n",
      "building tree 199 of 400\n",
      "building tree 200 of 400\n",
      "building tree 201 of 400\n",
      "building tree 202 of 400\n",
      "building tree 203 of 400\n",
      "building tree 204 of 400\n",
      "building tree 205 of 400\n",
      "building tree 206 of 400\n",
      "building tree 207 of 400\n",
      "building tree 208 of 400\n",
      "building tree 209 of 400\n",
      "building tree 210 of 400\n",
      "building tree 211 of 400\n",
      "building tree 212 of 400\n",
      "building tree 213 of 400\n",
      "building tree 214 of 400\n",
      "building tree 215 of 400\n",
      "building tree 216 of 400\n",
      "building tree 217 of 400\n",
      "building tree 218 of 400\n",
      "building tree 219 of 400\n",
      "building tree 220 of 400\n",
      "building tree 221 of 400\n",
      "building tree 222 of 400\n",
      "building tree 223 of 400\n",
      "building tree 224 of 400\n",
      "building tree 225 of 400\n",
      "building tree 226 of 400\n",
      "building tree 227 of 400\n",
      "building tree 228 of 400\n",
      "building tree 229 of 400\n",
      "building tree 230 of 400\n",
      "building tree 231 of 400\n",
      "building tree 232 of 400\n",
      "building tree 233 of 400\n",
      "building tree 234 of 400\n",
      "building tree 235 of 400\n",
      "building tree 236 of 400\n",
      "building tree 237 of 400\n",
      "building tree 238 of 400\n",
      "building tree 239 of 400\n",
      "building tree 240 of 400\n",
      "building tree 241 of 400\n",
      "building tree 242 of 400\n",
      "building tree 243 of 400\n",
      "building tree 244 of 400\n",
      "building tree 245 of 400\n",
      "building tree 246 of 400\n",
      "building tree 247 of 400\n",
      "building tree 248 of 400\n",
      "building tree 249 of 400\n",
      "building tree 250 of 400\n",
      "building tree 251 of 400\n",
      "building tree 252 of 400\n",
      "building tree 253 of 400\n",
      "building tree 254 of 400\n",
      "building tree 255 of 400\n",
      "building tree 256 of 400\n",
      "building tree 257 of 400\n",
      "building tree 258 of 400\n",
      "building tree 259 of 400\n",
      "building tree 260 of 400\n",
      "building tree 261 of 400\n",
      "building tree 262 of 400\n",
      "building tree 263 of 400\n",
      "building tree 264 of 400\n",
      "building tree 265 of 400\n",
      "building tree 266 of 400\n",
      "building tree 267 of 400\n",
      "building tree 268 of 400\n",
      "building tree 269 of 400\n",
      "building tree 270 of 400\n",
      "building tree 271 of 400\n",
      "building tree 272 of 400\n",
      "building tree 273 of 400\n",
      "building tree 274 of 400\n",
      "building tree 275 of 400\n",
      "building tree 276 of 400\n",
      "building tree 277 of 400\n",
      "building tree 278 of 400\n",
      "building tree 279 of 400\n",
      "building tree 280 of 400\n",
      "building tree 281 of 400\n",
      "building tree 282 of 400\n",
      "building tree 283 of 400\n",
      "building tree 284 of 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 23.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 285 of 400\n",
      "building tree 286 of 400\n",
      "building tree 287 of 400\n",
      "building tree 288 of 400\n",
      "building tree 289 of 400\n",
      "building tree 290 of 400\n",
      "building tree 291 of 400\n",
      "building tree 292 of 400\n",
      "building tree 293 of 400\n",
      "building tree 294 of 400\n",
      "building tree 295 of 400\n",
      "building tree 296 of 400\n",
      "building tree 297 of 400\n",
      "building tree 298 of 400\n",
      "building tree 299 of 400\n",
      "building tree 300 of 400\n",
      "building tree 301 of 400\n",
      "building tree 302 of 400\n",
      "building tree 303 of 400\n",
      "building tree 304 of 400\n",
      "building tree 305 of 400\n",
      "building tree 306 of 400\n",
      "building tree 307 of 400\n",
      "building tree 308 of 400\n",
      "building tree 309 of 400\n",
      "building tree 310 of 400\n",
      "building tree 311 of 400\n",
      "building tree 312 of 400\n",
      "building tree 313 of 400\n",
      "building tree 314 of 400\n",
      "building tree 315 of 400\n",
      "building tree 316 of 400\n",
      "building tree 317 of 400\n",
      "building tree 318 of 400\n",
      "building tree 319 of 400\n",
      "building tree 320 of 400\n",
      "building tree 321 of 400\n",
      "building tree 322 of 400\n",
      "building tree 323 of 400\n",
      "building tree 324 of 400\n",
      "building tree 325 of 400\n",
      "building tree 326 of 400\n",
      "building tree 327 of 400\n",
      "building tree 328 of 400\n",
      "building tree 329 of 400\n",
      "building tree 330 of 400\n",
      "building tree 331 of 400\n",
      "building tree 332 of 400\n",
      "building tree 333 of 400\n",
      "building tree 334 of 400\n",
      "building tree 335 of 400\n",
      "building tree 336 of 400\n",
      "building tree 337 of 400\n",
      "building tree 338 of 400\n",
      "building tree 339 of 400\n",
      "building tree 340 of 400\n",
      "building tree 341 of 400\n",
      "building tree 342 of 400\n",
      "building tree 343 of 400\n",
      "building tree 344 of 400\n",
      "building tree 345 of 400\n",
      "building tree 346 of 400\n",
      "building tree 347 of 400\n",
      "building tree 348 of 400\n",
      "building tree 349 of 400\n",
      "building tree 350 of 400\n",
      "building tree 351 of 400\n",
      "building tree 352 of 400\n",
      "building tree 353 of 400\n",
      "building tree 354 of 400\n",
      "building tree 355 of 400\n",
      "building tree 356 of 400\n",
      "building tree 357 of 400\n",
      "building tree 358 of 400\n",
      "building tree 359 of 400\n",
      "building tree 360 of 400\n",
      "building tree 361 of 400\n",
      "building tree 362 of 400\n",
      "building tree 363 of 400\n",
      "building tree 364 of 400\n",
      "building tree 365 of 400\n",
      "building tree 366 of 400\n",
      "building tree 367 of 400\n",
      "building tree 368 of 400\n",
      "building tree 369 of 400\n",
      "building tree 370 of 400\n",
      "building tree 371 of 400\n",
      "building tree 372 of 400\n",
      "building tree 373 of 400\n",
      "building tree 374 of 400\n",
      "building tree 375 of 400\n",
      "building tree 376 of 400\n",
      "building tree 377 of 400\n",
      "building tree 378 of 400\n",
      "building tree 379 of 400\n",
      "building tree 380 of 400\n",
      "building tree 381 of 400\n",
      "building tree 382 of 400\n",
      "building tree 383 of 400\n",
      "building tree 384 of 400\n",
      "building tree 385 of 400\n",
      "building tree 386 of 400\n",
      "building tree 387 of 400\n",
      "building tree 388 of 400\n",
      "building tree 389 of 400\n",
      "building tree 390 of 400\n",
      "building tree 391 of 400\n",
      "building tree 392 of 400\n",
      "building tree 393 of 400\n",
      "building tree 394 of 400\n",
      "building tree 395 of 400\n",
      "building tree 396 of 400\n",
      "building tree 397 of 400\n",
      "building tree 398 of 400\n",
      "building tree 399 of 400\n",
      "building tree 400 of 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed: 33.4min finished\n"
     ]
    }
   ],
   "source": [
    "rfc_grid_results = rfc_grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees = 400, Min Samples Leaf = 3, with an accuracy of 0.67308622613204.\n",
      "\n",
      "   param_random_forest__n_estimators param_random_forest__min_samples_leaf  \\\n",
      "0                                100                                     1   \n",
      "1                                200                                     1   \n",
      "2                                400                                     1   \n",
      "3                                100                                     3   \n",
      "4                                200                                     3   \n",
      "5                                400                                     3   \n",
      "6                                100                                     5   \n",
      "7                                200                                     5   \n",
      "8                                400                                     5   \n",
      "9                                100                                    10   \n",
      "10                               200                                    10   \n",
      "11                               400                                    10   \n",
      "\n",
      "    mean_test_score  \n",
      "0          0.664538  \n",
      "1          0.666446  \n",
      "2          0.667429  \n",
      "3          0.671907  \n",
      "4          0.672651  \n",
      "5          0.673086  \n",
      "6          0.670332  \n",
      "7          0.670771  \n",
      "8          0.670920  \n",
      "9          0.666534  \n",
      "10         0.667036  \n",
      "11         0.667137  \n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Trees = {bestn}, Min Samples Leaf = {bestMS}, with an accuracy of {bestScore}.\\n\".format(\n",
    "    bestn = rfc_grid_results.best_params_['random_forest__n_estimators'],\n",
    "    bestMS = rfc_grid_results.best_params_['random_forest__min_samples_leaf'],\n",
    "    bestScore = rfc_grid_results.best_score_))\n",
    "\n",
    "res = pd.DataFrame(rfc_grid_results.cv_results_)\n",
    "print(res[['param_random_forest__n_estimators',\n",
    "           'param_random_forest__min_samples_leaf',\n",
    "           'mean_test_score']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite 400 trees having the highest mean test score, it is only by .00035, and is computationally twice as expensive as 200 trees, which itself is only higher than 100 trees by .0007. We can always use a higher number of trees to get a marginally better test score, so with discretion, I am going to use 200 trees with min_samples_leaf = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 200building tree 2 of 200\n",
      "building tree 3 of 200\n",
      "\n",
      "building tree 4 of 200\n",
      "building tree 5 of 200\n",
      "building tree 6 of 200\n",
      "building tree 7 of 200\n",
      "building tree 8 of 200\n",
      "building tree 9 of 200\n",
      "building tree 10 of 200\n",
      "building tree 11 of 200\n",
      "building tree 12 of 200\n",
      "building tree 13 of 200\n",
      "building tree 14 of 200\n",
      "building tree 15 of 200\n",
      "building tree 16 of 200\n",
      "building tree 17 of 200\n",
      "building tree 18 of 200\n",
      "building tree 19 of 200\n",
      "building tree 20 of 200\n",
      "building tree 21 of 200\n",
      "building tree 22 of 200\n",
      "building tree 23 of 200\n",
      "building tree 24 of 200\n",
      "building tree 25 of 200building tree 26 of 200\n",
      "\n",
      "building tree 27 of 200\n",
      "building tree 28 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 29 of 200\n",
      "building tree 30 of 200\n",
      "building tree 31 of 200\n",
      "building tree 32 of 200\n",
      "building tree 33 of 200\n",
      "building tree 34 of 200\n",
      "building tree 35 of 200\n",
      "building tree 36 of 200\n",
      "building tree 37 of 200\n",
      "building tree 38 of 200\n",
      "building tree 39 of 200\n",
      "building tree 40 of 200\n",
      "building tree 41 of 200\n",
      "building tree 42 of 200\n",
      "building tree 43 of 200\n",
      "building tree 44 of 200\n",
      "building tree 45 of 200\n",
      "building tree 46 of 200\n",
      "building tree 47 of 200\n",
      "building tree 48 of 200\n",
      "building tree 49 of 200\n",
      "building tree 50 of 200\n",
      "building tree 51 of 200\n",
      "building tree 52 of 200\n",
      "building tree 53 of 200\n",
      "building tree 54 of 200\n",
      "building tree 55 of 200\n",
      "building tree 56 of 200\n",
      "building tree 57 of 200\n",
      "building tree 58 of 200\n",
      "building tree 59 of 200\n",
      "building tree 60 of 200\n",
      "building tree 61 of 200\n",
      "building tree 62 of 200\n",
      "building tree 63 of 200\n",
      "building tree 64 of 200\n",
      "building tree 65 of 200\n",
      "building tree 66 of 200building tree 67 of 200\n",
      "\n",
      "building tree 68 of 200\n",
      "building tree 69 of 200\n",
      "building tree 70 of 200\n",
      "building tree 71 of 200\n",
      "building tree 72 of 200\n",
      "building tree 73 of 200\n",
      "building tree 74 of 200\n",
      "building tree 75 of 200\n",
      "building tree 76 of 200\n",
      "building tree 77 of 200\n",
      "building tree 78 of 200\n",
      "building tree 79 of 200\n",
      "building tree 80 of 200\n",
      "building tree 81 of 200\n",
      "building tree 82 of 200\n",
      "building tree 83 of 200\n",
      "building tree 84 of 200\n",
      "building tree 85 of 200\n",
      "building tree 86 of 200\n",
      "building tree 87 of 200\n",
      "building tree 88 of 200\n",
      "building tree 89 of 200\n",
      "building tree 90 of 200\n",
      "building tree 91 of 200\n",
      "building tree 92 of 200\n",
      "building tree 93 of 200\n",
      "building tree 94 of 200\n",
      "building tree 95 of 200\n",
      "building tree 96 of 200\n",
      "building tree 97 of 200\n",
      "building tree 98 of 200\n",
      "building tree 99 of 200\n",
      "building tree 100 of 200\n",
      "building tree 101 of 200\n",
      "building tree 102 of 200\n",
      "building tree 103 of 200\n",
      "building tree 104 of 200\n",
      "building tree 105 of 200\n",
      "building tree 106 of 200\n",
      "building tree 107 of 200\n",
      "building tree 108 of 200\n",
      "building tree 109 of 200\n",
      "building tree 110 of 200\n",
      "building tree 111 of 200\n",
      "building tree 112 of 200\n",
      "building tree 113 of 200\n",
      "building tree 114 of 200\n",
      "building tree 115 of 200\n",
      "building tree 116 of 200\n",
      "building tree 117 of 200\n",
      "building tree 118 of 200\n",
      "building tree 119 of 200\n",
      "building tree 120 of 200\n",
      "building tree 121 of 200\n",
      "building tree 122 of 200\n",
      "building tree 123 of 200\n",
      "building tree 124 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 10.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 125 of 200\n",
      "building tree 126 of 200\n",
      "building tree 127 of 200\n",
      "building tree 128 of 200\n",
      "building tree 129 of 200\n",
      "building tree 130 of 200\n",
      "building tree 131 of 200\n",
      "building tree 132 of 200\n",
      "building tree 133 of 200\n",
      "building tree 134 of 200\n",
      "building tree 135 of 200\n",
      "building tree 136 of 200\n",
      "building tree 137 of 200\n",
      "building tree 138 of 200building tree 139 of 200\n",
      "\n",
      "building tree 140 of 200\n",
      "building tree 141 of 200\n",
      "building tree 142 of 200\n",
      "building tree 143 of 200\n",
      "building tree 144 of 200\n",
      "building tree 145 of 200\n",
      "building tree 146 of 200\n",
      "building tree 147 of 200\n",
      "building tree 148 of 200\n",
      "building tree 149 of 200\n",
      "building tree 150 of 200\n",
      "building tree 151 of 200\n",
      "building tree 152 of 200\n",
      "building tree 153 of 200\n",
      "building tree 154 of 200\n",
      "building tree 155 of 200\n",
      "building tree 156 of 200\n",
      "building tree 157 of 200\n",
      "building tree 158 of 200\n",
      "building tree 159 of 200\n",
      "building tree 160 of 200\n",
      "building tree 161 of 200\n",
      "building tree 162 of 200\n",
      "building tree 163 of 200\n",
      "building tree 164 of 200\n",
      "building tree 165 of 200\n",
      "building tree 166 of 200\n",
      "building tree 167 of 200\n",
      "building tree 168 of 200\n",
      "building tree 169 of 200\n",
      "building tree 170 of 200\n",
      "building tree 171 of 200\n",
      "building tree 172 of 200\n",
      "building tree 173 of 200\n",
      "building tree 174 of 200\n",
      "building tree 175 of 200\n",
      "building tree 176 of 200\n",
      "building tree 177 of 200\n",
      "building tree 178 of 200\n",
      "building tree 179 of 200\n",
      "building tree 180 of 200\n",
      "building tree 181 of 200\n",
      "building tree 182 of 200\n",
      "building tree 183 of 200\n",
      "building tree 184 of 200\n",
      "building tree 185 of 200\n",
      "building tree 186 of 200\n",
      "building tree 187 of 200\n",
      "building tree 188 of 200\n",
      "building tree 189 of 200\n",
      "building tree 190 of 200\n",
      "building tree 191 of 200\n",
      "building tree 192 of 200\n",
      "building tree 193 of 200\n",
      "building tree 194 of 200\n",
      "building tree 195 of 200\n",
      "building tree 196 of 200\n",
      "building tree 197 of 200\n",
      "building tree 198 of 200\n",
      "building tree 199 of 200\n",
      "building tree 200 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 16.9min finished\n"
     ]
    }
   ],
   "source": [
    "rfc_pipe.set_params(random_forest__n_estimators = 200, random_forest__min_samples_leaf = 3)\n",
    "\n",
    "rfc = fitmodel(model = rfc_pipe,\n",
    "               filename = \"models/random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'log_loss',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.GradientBoostingClassifier().get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to tune max_depth and min_samples_leaf, as well as learning rate and n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = game_train.sample(50000, random_state= 49)\n",
    "\n",
    "X_sample = train_sample.loc[:,game_train.columns != \"p1_won\"]\n",
    "y_sample = train_sample[\"p1_won\"]\n",
    "\n",
    "gbc_predictors = list(set(game_train.head()).difference({\"p1_won\",\"p1_id\",\"p2_id\"}))\n",
    "\n",
    "gbc_pipe = rfc_pipe = Pipeline(steps = [\n",
    "            (\"predictors\", ColumnTransformer([(\"predictors\",\"passthrough\",gbc_predictors)])),\n",
    "            (\"boosted_tree\", ensemble.GradientBoostingClassifier(verbose = 1, n_estimators = 100, random_state = 21))\n",
    "            ])\n",
    "\n",
    "gbc_grid = dict(boosted_tree__n_estimators = [100, 250, 500, 1000],\n",
    "                boosted_tree__max_depth = [2, 3, 4, 5],\n",
    "                boosted_tree__min_samples_leaf = [1, 3, 5, 10],\n",
    "                boosted_tree__learning_rate = [.001, .01, .1, .2]\n",
    "                )\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=2).split(X_sample,y_sample)\n",
    "\n",
    "gbc_grid_search = GridSearchCV(estimator = gbc_pipe,\n",
    "                               param_grid = gbc_grid,\n",
    "                               n_jobs = 4,\n",
    "                               cv = game_folded,\n",
    "                               scoring = 'accuracy',\n",
    "                               error_score = 0,\n",
    "                               verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 256 candidates, totalling 512 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3616           44.13s\n",
      "         2           1.3431           43.19s\n",
      "         3           1.3287           43.32s\n",
      "         4           1.3179           43.34s\n",
      "         5           1.3090           43.02s\n",
      "         6           1.3011           43.19s\n",
      "         7           1.2958           42.79s\n",
      "         8           1.2904           42.81s\n",
      "         9           1.2858           42.56s\n",
      "        10           1.2822           42.46s\n",
      "        20           1.2637           40.95s\n",
      "        30           1.2553           39.72s\n",
      "        40           1.2471           38.85s\n",
      "        50           1.2409           37.98s\n",
      "        60           1.2352           37.08s\n",
      "        70           1.2307           36.12s\n",
      "        80           1.2281           35.15s\n",
      "        90           1.2235           34.39s\n",
      "       100           1.2191           33.65s\n",
      "       200           1.1873           25.21s\n",
      "       300           1.1704           16.74s\n",
      "       400           1.1596            8.35s\n",
      "       500           1.1504            0.00s\n"
     ]
    }
   ],
   "source": [
    "gbc_grid_result = gbc_grid_search.fit(X_sample,y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees = 500, Learning Rate = 0.2, Min Samples Leaf = 3, Max Depth = 2, with an accuracy of 0.66928.\n",
      "\n",
      "    param_boosted_tree__max_depth  mean_test_score\n",
      "0                               2          0.59228\n",
      "1                               2          0.61034\n",
      "2                               2          0.61558\n",
      "3                               2          0.62490\n",
      "4                               2          0.59228\n",
      "..                            ...              ...\n",
      "251                             5          0.64458\n",
      "252                             5          0.66192\n",
      "253                             5          0.65880\n",
      "254                             5          0.65242\n",
      "255                             5          0.64436\n",
      "\n",
      "[256 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19f225b4d00>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Number of trees = {bestn}, Learning Rate = {bestLR}, Min Samples Leaf = {bestMS}, Max Depth = {bestMD}, with an accuracy of {bestScore}.\\n\".format(\n",
    "    \n",
    "    bestn = gbc_grid_result.best_params_['boosted_tree__n_estimators'],\n",
    "    bestLR = gbc_grid_result.best_params_['boosted_tree__learning_rate'],\n",
    "    bestMS = gbc_grid_result.best_params_['boosted_tree__min_samples_leaf'],\n",
    "    bestMD = gbc_grid_result.best_params_['boosted_tree__max_depth'],\n",
    "    bestScore = gbc_grid_result.best_score_))\n",
    "\n",
    "res = pd.DataFrame(gbc_grid_result.cv_results_)\n",
    "\n",
    "print(res[['param_boosted_tree__max_depth',\n",
    "           'mean_test_score']])\n",
    "\n",
    "plt.plot(res['param_boosted_tree__max_depth'], res['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3621           23.91m\n",
      "         2           1.3448           23.38m\n",
      "         3           1.3310           23.14m\n",
      "         4           1.3204           22.77m\n",
      "         5           1.3115           22.75m\n",
      "         6           1.3045           22.63m\n",
      "         7           1.2986           22.67m\n",
      "         8           1.2936           22.69m\n",
      "         9           1.2896           22.59m\n",
      "        10           1.2856           22.41m\n",
      "        20           1.2676           21.82m\n",
      "        30           1.2599           21.31m\n",
      "        40           1.2544           20.72m\n",
      "        50           1.2505           20.15m\n",
      "        60           1.2452           19.67m\n",
      "        70           1.2382           19.26m\n",
      "        80           1.2328           18.83m\n",
      "        90           1.2292           18.35m\n",
      "       100           1.2258           17.89m\n",
      "       200           1.2023           13.40m\n",
      "       300           1.1894            8.93m\n",
      "       400           1.1815            4.47m\n",
      "       500           1.1762            0.00s\n",
      "[CV] END ................................ score: (test=0.680) total time=22.6min\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 22.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3624           22.61m\n",
      "         2           1.3443           22.70m\n",
      "         3           1.3312           22.63m\n",
      "         4           1.3205           22.58m\n",
      "         5           1.3122           22.32m\n",
      "         6           1.3051           22.37m\n",
      "         7           1.2992           22.19m\n",
      "         8           1.2944           22.17m\n",
      "         9           1.2900           21.99m\n",
      "        10           1.2861           21.95m\n",
      "        20           1.2679           21.44m\n",
      "        30           1.2606           20.97m\n",
      "        40           1.2558           20.41m\n",
      "        50           1.2520           20.18m\n",
      "        60           1.2453           20.61m\n",
      "        70           1.2409           20.76m\n",
      "        80           1.2355           20.08m\n",
      "        90           1.2300           19.50m\n",
      "       100           1.2257           18.93m\n",
      "       200           1.2020           13.77m\n",
      "       300           1.1908            9.05m\n",
      "       400           1.1821            4.46m\n",
      "       500           1.1775            0.00s\n",
      "[CV] END ................................ score: (test=0.680) total time=22.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 44.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 44.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.67963905, 0.68006475])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_pipe.set_params(boosted_tree__max_depth = 2, boosted_tree__n_estimators = 500, boosted_tree__learning_rate = 0.2, boosted_tree__min_samples_leaf = 3)\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=2).split(X,y)\n",
    "\n",
    "cross_val_score(estimator = gbc_pipe,\n",
    "                n_jobs = 1,\n",
    "                cv = game_folded,\n",
    "                X = X,\n",
    "                y = y,\n",
    "                scoring = 'accuracy',\n",
    "                error_score = 0,\n",
    "                verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3698           73.62m\n",
      "         2           1.3557           72.12m\n",
      "         3           1.3439           71.69m\n",
      "         4           1.3336           71.28m\n",
      "         5           1.3250           71.65m\n",
      "         6           1.3175           71.37m\n",
      "         7           1.3112           71.37m\n",
      "         8           1.3055           71.00m\n",
      "         9           1.3006           71.07m\n",
      "        10           1.2964           71.06m\n",
      "        20           1.2724           69.62m\n",
      "        30           1.2617           67.85m\n",
      "        40           1.2555           66.20m\n",
      "        50           1.2502           64.88m\n",
      "        60           1.2467           63.53m\n",
      "        70           1.2436           62.32m\n",
      "        80           1.2398           61.34m\n",
      "        90           1.2368           60.44m\n",
      "       100           1.2337           59.64m\n",
      "       200           1.2133           51.93m\n",
      "       300           1.1972           46.31m\n",
      "       400           1.1864           39.74m\n"
     ]
    }
   ],
   "source": [
    "gbc_pipe.set_params(boosted_tree__max_depth = 3, boosted_tree__n_estimators = 1000, boosted_tree__learning_rate = 0.1, boosted_tree__min_samples_leaf = 3)\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=2).split(X,y)\n",
    "\n",
    "cross_val_score(estimator = gbc_pipe,\n",
    "                n_jobs = 1,\n",
    "                cv = game_folded,\n",
    "                X = X,\n",
    "                y = y,\n",
    "                scoring = 'accuracy',\n",
    "                error_score = 0,\n",
    "                verbose = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
