{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_id</th>\n",
       "      <th>p2_id</th>\n",
       "      <th>p1_won</th>\n",
       "      <th>p1_games_played</th>\n",
       "      <th>p1_games_won</th>\n",
       "      <th>p2_games_played</th>\n",
       "      <th>p2_games_won</th>\n",
       "      <th>p1_char.-1</th>\n",
       "      <th>p1_char.banjokazooie</th>\n",
       "      <th>p1_char.bayonetta</th>\n",
       "      <th>...</th>\n",
       "      <th>stage.Town and City</th>\n",
       "      <th>stage.Unova Pokemon League</th>\n",
       "      <th>stage.Unova Pokémon League</th>\n",
       "      <th>stage.Venom</th>\n",
       "      <th>stage.WarioWare</th>\n",
       "      <th>stage.Wily Castle</th>\n",
       "      <th>stage.Yggdrasil's Altar</th>\n",
       "      <th>stage.Yoshi's Island</th>\n",
       "      <th>stage.Yoshi's Island (Melee)</th>\n",
       "      <th>stage.Yoshi's Story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1472816</td>\n",
       "      <td>1075251</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1075251</td>\n",
       "      <td>1472816</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>challonge__MrRiceman</td>\n",
       "      <td>challonge__Loconotcoco</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leo</td>\n",
       "      <td>1272809</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1034645</td>\n",
       "      <td>1302612</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963854</th>\n",
       "      <td>30896</td>\n",
       "      <td>4702</td>\n",
       "      <td>False</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>865</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963855</th>\n",
       "      <td>4702</td>\n",
       "      <td>30896</td>\n",
       "      <td>True</td>\n",
       "      <td>865</td>\n",
       "      <td>555</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963856</th>\n",
       "      <td>1263104</td>\n",
       "      <td>53481</td>\n",
       "      <td>True</td>\n",
       "      <td>186</td>\n",
       "      <td>112</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963857</th>\n",
       "      <td>53481</td>\n",
       "      <td>1263104</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>186</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963858</th>\n",
       "      <td>230918</td>\n",
       "      <td>30044</td>\n",
       "      <td>False</td>\n",
       "      <td>212</td>\n",
       "      <td>120</td>\n",
       "      <td>79</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963859 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        p1_id                   p2_id  p1_won  \\\n",
       "0                     1472816                 1075251   False   \n",
       "1                     1075251                 1472816    True   \n",
       "2        challonge__MrRiceman  challonge__Loconotcoco   False   \n",
       "3                         Leo                 1272809    True   \n",
       "4                     1034645                 1302612    True   \n",
       "...                       ...                     ...     ...   \n",
       "2963854                 30896                    4702   False   \n",
       "2963855                  4702                   30896    True   \n",
       "2963856               1263104                   53481    True   \n",
       "2963857                 53481                 1263104   False   \n",
       "2963858                230918                   30044   False   \n",
       "\n",
       "         p1_games_played  p1_games_won  p2_games_played  p2_games_won  \\\n",
       "0                      2             0               23            13   \n",
       "1                     23            13                2             0   \n",
       "2                      4             1                2             1   \n",
       "3                      1             1              102            49   \n",
       "4                     77            40                2             0   \n",
       "...                  ...           ...              ...           ...   \n",
       "2963854               72            51              865           555   \n",
       "2963855              865           555               72            51   \n",
       "2963856              186           112                8             7   \n",
       "2963857                8             7              186           112   \n",
       "2963858              212           120               79            53   \n",
       "\n",
       "         p1_char.-1  p1_char.banjokazooie  p1_char.bayonetta  ...  \\\n",
       "0                 0                     0                  0  ...   \n",
       "1                 0                     0                  0  ...   \n",
       "2                 0                     0                  0  ...   \n",
       "3                 0                     0                  0  ...   \n",
       "4                 0                     0                  0  ...   \n",
       "...             ...                   ...                ...  ...   \n",
       "2963854           0                     0                  0  ...   \n",
       "2963855           0                     0                  0  ...   \n",
       "2963856           0                     0                  0  ...   \n",
       "2963857           0                     0                  0  ...   \n",
       "2963858           0                     0                  0  ...   \n",
       "\n",
       "         stage.Town and City  stage.Unova Pokemon League  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "...                      ...                         ...   \n",
       "2963854                    0                           0   \n",
       "2963855                    0                           0   \n",
       "2963856                    0                           0   \n",
       "2963857                    0                           0   \n",
       "2963858                    0                           0   \n",
       "\n",
       "         stage.Unova Pokémon League  stage.Venom  stage.WarioWare  \\\n",
       "0                                 0            0                0   \n",
       "1                                 0            0                0   \n",
       "2                                 0            0                0   \n",
       "3                                 0            0                0   \n",
       "4                                 0            0                0   \n",
       "...                             ...          ...              ...   \n",
       "2963854                           0            0                0   \n",
       "2963855                           0            0                0   \n",
       "2963856                           0            0                0   \n",
       "2963857                           0            0                0   \n",
       "2963858                           0            0                0   \n",
       "\n",
       "         stage.Wily Castle  stage.Yggdrasil's Altar  stage.Yoshi's Island  \\\n",
       "0                        0                        0                     0   \n",
       "1                        0                        0                     0   \n",
       "2                        0                        0                     0   \n",
       "3                        0                        0                     0   \n",
       "4                        0                        0                     0   \n",
       "...                    ...                      ...                   ...   \n",
       "2963854                  0                        0                     0   \n",
       "2963855                  0                        0                     0   \n",
       "2963856                  0                        0                     0   \n",
       "2963857                  0                        0                     0   \n",
       "2963858                  0                        0                     0   \n",
       "\n",
       "         stage.Yoshi's Island (Melee)  stage.Yoshi's Story  \n",
       "0                                   0                    0  \n",
       "1                                   0                    0  \n",
       "2                                   0                    0  \n",
       "3                                   0                    0  \n",
       "4                                   0                    0  \n",
       "...                               ...                  ...  \n",
       "2963854                             0                    0  \n",
       "2963855                             0                    0  \n",
       "2963856                             0                    0  \n",
       "2963857                             0                    0  \n",
       "2963858                             0                    0  \n",
       "\n",
       "[2963859 rows x 237 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_data = pd.read_csv(\"../Data/data/clean_game_data.csv\",dtype={\"p1_id\" : \"string\",\"p2_id\" : \"string\",\"p1_char\" : \"string\", \"p2_char\" : \"string\", \"stage\" : \"string\", \"p1_games_played\" : \"int32\", \"p1_games_won\" : \"int32\", \"p2_games_played\" : \"int32\", \"p2_games_won\" : \"int32\", \"p1_won\" : \"bool\"})\n",
    "game_data = pd.get_dummies(game_data, columns=[\"p1_char\",\"p2_char\",\"stage\"], prefix_sep=\".\", )\n",
    "game_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `sklearn`, there aren't recipes. Instead, there are pipelines, which works a bit like a recipe and a workflow combined. We can apply transformations to our data including selecting predictors, normalizing variables, and adding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_train, game_test = train_test_split(game_data, train_size = 0.8, stratify = game_data[[\"p1_won\"]], random_state=2049)\n",
    "\n",
    "# We stratified on our response, p1_won. \n",
    "# This shouldn't make too much of a difference because we randomized which is p1 and p2, however it is still good practice.\n",
    "\n",
    "X = game_train.loc[:,game_train.columns != \"p1_won\"]\n",
    "y = game_train[\"p1_won\"]\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=5).split(X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by using our numerical predictors to fit a linear model. We want to use a logistic regression because we are predicting a binary class. We're going to score by accuracy because there is no class imbalance present (because we randomized p1_won) and accuracy is much easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x = [True, False], height = game_train[\"p1_won\"].value_counts() / len(game_train))\n",
    "plt.xticks([True, False], [\"True\", \"False\"])\n",
    "plt.title(\"p1_won True vs False\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitmodel(model, filename, df = game_train):\n",
    "    \n",
    "    if not os.path.isfile(filename):\n",
    "\n",
    "        model.fit(X,y)\n",
    "\n",
    "        joblib.dump(model, filename)\n",
    "\n",
    "    else:\n",
    "        modeltemp = joblib.load(filename)\n",
    "        if (type(model) != type(modeltemp)) or \\\n",
    "            (tuple([k[0] for k in model.steps]) != tuple([k[0] for k in modeltemp.steps])):\n",
    "            print (\"\\033[93m Warning: model mismatch. Delete the file {filename} and rerun or risk faulty models.\\n \\033[0m\".format(filename=filename))\n",
    "        model = modeltemp\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's fit a logistic regression with no penalty. For this and the elastic net, we'll just use the numerical predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6433 accuracy with a standard deviation of 0.0007.\n"
     ]
    }
   ],
   "source": [
    "lm_predictors = [\"p1_games_played\",\"p2_games_played\",\"p1_games_won\",\"p2_games_won\"]\n",
    "\n",
    "lm_pipe = Pipeline(steps = [\n",
    "    (\"predictors\", ColumnTransformer([(\"predictors\",\"passthrough\",lm_predictors)])),\n",
    "    (\"logistic\", linear_model.LogisticRegression(penalty=None))\n",
    "    ])\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=5).split(X,y)\n",
    "\n",
    "lm_cross_val = cross_val_score(estimator = lm_pipe,\n",
    "                               cv = game_folded,\n",
    "                               scoring = 'accuracy'\n",
    "                               X = X,\n",
    "                               y = y)\n",
    "\n",
    "print(\"%0.4f accuracy with a standard deviation of %0.4f.\" % (lm_cross_val.mean(), lm_cross_val.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = fitmodel(model = lm_pipe,\n",
    "              filename = \"models/logistic_regression.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to use an elastic net and tune the parameter `l1_ratio`, which gives the proportion of lasso regression to ridge regression. A value of `1.0` is expressed as a lasso regression, `0.0` is expressed as a ridge regression, and anything in between is some sort of elastic net. \n",
    "\n",
    "We can also tune C, a hyperparameter which controls penalty strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_predictors = [\"p1_games_played\",\"p2_games_played\",\"p1_games_won\",\"p2_games_won\"]\n",
    "\n",
    "en_pipe = Pipeline(steps = [\n",
    "    (\"predictors\", ColumnTransformer([(\"predictors\",\"passthrough\",en_predictors)])),\n",
    "    (\"logistic\", linear_model.LogisticRegression(solver='saga',penalty='elasticnet'))\n",
    "    ])\n",
    "\n",
    "en_grid = dict(logistic__l1_ratio = [0.0, 0.10, 0.25, 0.50, 0.75, 0.90, 1.0],\n",
    "               logistic__C = [1000, 100, 10, 1.0, 0.1, 0.01, 0.001])\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=5).split(X,y)\n",
    "\n",
    "en_grid_search = GridSearchCV(estimator = en_pipe,\n",
    "                            param_grid = en_grid,\n",
    "                            n_jobs = 1,\n",
    "                            cv = game_folded,\n",
    "                            scoring = 'accuracy',\n",
    "                            error_score = 0,\n",
    "                            verbose = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "[CV 1/5] END logistic__C=1000, logistic__l1_ratio=0.0;, score=0.679 total time=   7.2s\n",
      "[CV 2/5] END logistic__C=1000, logistic__l1_ratio=0.0;, score=0.679 total time=   7.2s\n",
      "[CV 3/5] END logistic__C=1000, logistic__l1_ratio=0.0;, score=0.679 total time=   7.1s\n",
      "[CV 4/5] END logistic__C=1000, logistic__l1_ratio=0.0;, score=0.681 total time=   7.7s\n",
      "[CV 5/5] END logistic__C=1000, logistic__l1_ratio=0.0;, score=0.680 total time=   7.0s\n",
      "[CV 1/5] END logistic__C=1000, logistic__l1_ratio=0.1;, score=0.679 total time=   7.2s\n",
      "[CV 2/5] END logistic__C=1000, logistic__l1_ratio=0.1;, score=0.679 total time=   7.3s\n",
      "[CV 3/5] END logistic__C=1000, logistic__l1_ratio=0.1;, score=0.679 total time=   7.2s\n",
      "[CV 4/5] END logistic__C=1000, logistic__l1_ratio=0.1;, score=0.681 total time=   7.3s\n",
      "[CV 5/5] END logistic__C=1000, logistic__l1_ratio=0.1;, score=0.680 total time=   7.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m en_grid_result \u001b[39m=\u001b[39m en_grid_search\u001b[39m.\u001b[39;49mfit(X[en_predictors],y) \u001b[39m# We pass in X[en_predictors] because the result is the same but slightly faster.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1289\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1291\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[0;32m   1292\u001b[0m     path_func(\n\u001b[0;32m   1293\u001b[0m         X,\n\u001b[0;32m   1294\u001b[0m         y,\n\u001b[0;32m   1295\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[0;32m   1296\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1297\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1298\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1299\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1300\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1301\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1302\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[0;32m   1303\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1304\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m   1305\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1306\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1307\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1308\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[0;32m   1309\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1310\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1311\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[0;32m   1312\u001b[0m     )\n\u001b[0;32m   1313\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[0;32m   1314\u001b[0m )\n\u001b[0;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:524\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    521\u001b[0m         alpha \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m l1_ratio)\n\u001b[0;32m    522\u001b[0m         beta \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m l1_ratio\n\u001b[1;32m--> 524\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[39m=\u001b[39m sag_solver(\n\u001b[0;32m    525\u001b[0m         X,\n\u001b[0;32m    526\u001b[0m         target,\n\u001b[0;32m    527\u001b[0m         sample_weight,\n\u001b[0;32m    528\u001b[0m         loss,\n\u001b[0;32m    529\u001b[0m         alpha,\n\u001b[0;32m    530\u001b[0m         beta,\n\u001b[0;32m    531\u001b[0m         max_iter,\n\u001b[0;32m    532\u001b[0m         tol,\n\u001b[0;32m    533\u001b[0m         verbose,\n\u001b[0;32m    534\u001b[0m         random_state,\n\u001b[0;32m    535\u001b[0m         \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    536\u001b[0m         max_squared_sum,\n\u001b[0;32m    537\u001b[0m         warm_start_sag,\n\u001b[0;32m    538\u001b[0m         is_saga\u001b[39m=\u001b[39;49m(solver \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    539\u001b[0m     )\n\u001b[0;32m    541\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    543\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msolver must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m solver\n\u001b[0;32m    545\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:325\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent sag implementation does not handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    324\u001b[0m sag \u001b[39m=\u001b[39m sag64 \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64 \u001b[39melse\u001b[39;00m sag32\n\u001b[1;32m--> 325\u001b[0m num_seen, n_iter_ \u001b[39m=\u001b[39m sag(\n\u001b[0;32m    326\u001b[0m     dataset,\n\u001b[0;32m    327\u001b[0m     coef_init,\n\u001b[0;32m    328\u001b[0m     intercept_init,\n\u001b[0;32m    329\u001b[0m     n_samples,\n\u001b[0;32m    330\u001b[0m     n_features,\n\u001b[0;32m    331\u001b[0m     n_classes,\n\u001b[0;32m    332\u001b[0m     tol,\n\u001b[0;32m    333\u001b[0m     max_iter,\n\u001b[0;32m    334\u001b[0m     loss,\n\u001b[0;32m    335\u001b[0m     step_size,\n\u001b[0;32m    336\u001b[0m     alpha_scaled,\n\u001b[0;32m    337\u001b[0m     beta_scaled,\n\u001b[0;32m    338\u001b[0m     sum_gradient_init,\n\u001b[0;32m    339\u001b[0m     gradient_memory_init,\n\u001b[0;32m    340\u001b[0m     seen_init,\n\u001b[0;32m    341\u001b[0m     num_seen_init,\n\u001b[0;32m    342\u001b[0m     fit_intercept,\n\u001b[0;32m    343\u001b[0m     intercept_sum_gradient,\n\u001b[0;32m    344\u001b[0m     intercept_decay,\n\u001b[0;32m    345\u001b[0m     is_saga,\n\u001b[0;32m    346\u001b[0m     verbose,\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    349\u001b[0m \u001b[39mif\u001b[39;00m n_iter_ \u001b[39m==\u001b[39m max_iter:\n\u001b[0;32m    350\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    351\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    352\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    353\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "en_grid_result = en_grid_search.fit(X[en_predictors],y) # We pass in X[en_predictors] because the result is the same but slightly faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01, l1_ratio = 1.0, with an accuracy of 0.6431155838173498.\n",
      "\n",
      "   param_logistic__l1_ratio param_logistic__C  mean_test_score\n",
      "0                       0.0              1000         0.643111\n",
      "1                       0.1              1000         0.643091\n",
      "2                      0.25              1000         0.643102\n",
      "3                       0.5              1000         0.643092\n",
      "4                      0.75              1000         0.643100\n",
      "5                       0.9              1000         0.643089\n",
      "6                       1.0              1000         0.643097\n",
      "7                       0.0               100         0.643077\n",
      "8                       0.1               100         0.643110\n",
      "9                      0.25               100         0.643108\n",
      "10                      0.5               100         0.643092\n",
      "11                     0.75               100         0.643105\n",
      "12                      0.9               100         0.643094\n",
      "13                      1.0               100         0.643107\n",
      "14                      0.0                10         0.643084\n",
      "15                      0.1                10         0.643113\n",
      "16                     0.25                10         0.643109\n",
      "17                      0.5                10         0.643092\n",
      "18                     0.75                10         0.643090\n",
      "19                      0.9                10         0.643100\n",
      "20                      1.0                10         0.643104\n",
      "21                      0.0               1.0         0.643085\n",
      "22                      0.1               1.0         0.643099\n",
      "23                     0.25               1.0         0.643100\n",
      "24                      0.5               1.0         0.643093\n",
      "25                     0.75               1.0         0.643107\n",
      "26                      0.9               1.0         0.643094\n",
      "27                      1.0               1.0         0.643114\n",
      "28                      0.0               0.1         0.643106\n",
      "29                      0.1               0.1         0.643093\n",
      "30                     0.25               0.1         0.643096\n",
      "31                      0.5               0.1         0.643099\n",
      "32                     0.75               0.1         0.643105\n",
      "33                      0.9               0.1         0.643113\n",
      "34                      1.0               0.1         0.643092\n",
      "35                      0.0              0.01         0.643079\n",
      "36                      0.1              0.01         0.643081\n",
      "37                     0.25              0.01         0.643097\n",
      "38                      0.5              0.01         0.643086\n",
      "39                     0.75              0.01         0.643089\n",
      "40                      0.9              0.01         0.643105\n",
      "41                      1.0              0.01         0.643116\n",
      "42                      0.0             0.001         0.643110\n",
      "43                      0.1             0.001         0.643100\n",
      "44                     0.25             0.001         0.643102\n",
      "45                      0.5             0.001         0.643094\n",
      "46                     0.75             0.001         0.643106\n",
      "47                      0.9             0.001         0.643100\n",
      "48                      1.0             0.001         0.643099\n"
     ]
    }
   ],
   "source": [
    "print(\"C = {bestC}, l1_ratio = {bestratio}, with an accuracy of {bestScore}.\\n\".format(\n",
    "    bestC = en_grid_result.best_params_['logistic__C'],\n",
    "    bestratio = en_grid_result.best_params_['logistic__l1_ratio'],\n",
    "    bestScore = en_grid_result.best_score_))\n",
    "\n",
    "res = pd.DataFrame(en_grid_result.cv_results_)\n",
    "print(res[['param_logistic__l1_ratio','param_logistic__C','mean_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pipe.set_params(logistic__C = 0.01, logistic__l1_ratio = 1.0)\n",
    "en = fitmodel(model = en_pipe,\n",
    "              filename = \"models/elastic_net.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to keep in mind is that games played and games won are relative to the size of the dataset, so it might be a good idea to use a proportion between players instead in case someone wants to use the final model on a dataset which is not of the same size. It's unclear if this will matter though.\n",
    "\n",
    "The goal of this project is more interpretation/inference than predicition, so we can hold this thought for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictors = list(set(game_train.head()).difference({\"p1_won\",\"p1_id\",\"p2_id\"}))\n",
    "\n",
    "dtc_pipe = Pipeline(steps = [\n",
    "    (\"predictors\", ColumnTransformer([(\"predictors\",\"passthrough\",dtc_predictors)])),\n",
    "    (\"decision_tree\", tree.DecisionTreeClassifier(random_state = 42))\n",
    "    ])\n",
    "\n",
    "dtc_grid = dict(decision_tree__ccp_alpha = [0.000, 0.005, 0.010, 0.020],\n",
    "                decision_tree__max_depth = [3, 5, 10, None],\n",
    "                decision_tree__min_samples_leaf = [1, 3, 5, 10])\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=5).split(X,y)\n",
    "\n",
    "dtc_grid_search = GridSearchCV(estimator = dtc_pipe,\n",
    "                               param_grid = dtc_grid,\n",
    "                               n_jobs = 4,\n",
    "                               cv = game_folded,\n",
    "                               scoring = 'accuracy',\n",
    "                               error_score = 0,\n",
    "                               verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dtc_grid_result \u001b[39m=\u001b[39m dtc_grid_search\u001b[39m.\u001b[39;49mfit(X[dtc_predictors],y)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 440\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtc_grid_result = dtc_grid_search.fit(X[dtc_predictors],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Features = None, Max Depth = 10, Min Samples Leaf = 10, with an accuracy of 0.646869980057419.\n",
      "\n",
      "   param_decision_tree__max_features param_decision_tree__max_depth  \\\n",
      "0                               sqrt                              3   \n",
      "1                               sqrt                              3   \n",
      "2                               sqrt                              3   \n",
      "3                               sqrt                              3   \n",
      "4                               log2                              3   \n",
      "5                               log2                              3   \n",
      "6                               log2                              3   \n",
      "7                               log2                              3   \n",
      "8                               None                              3   \n",
      "9                               None                              3   \n",
      "10                              None                              3   \n",
      "11                              None                              3   \n",
      "12                              sqrt                              5   \n",
      "13                              sqrt                              5   \n",
      "14                              sqrt                              5   \n",
      "15                              sqrt                              5   \n",
      "16                              log2                              5   \n",
      "17                              log2                              5   \n",
      "18                              log2                              5   \n",
      "19                              log2                              5   \n",
      "20                              None                              5   \n",
      "21                              None                              5   \n",
      "22                              None                              5   \n",
      "23                              None                              5   \n",
      "24                              sqrt                             10   \n",
      "25                              sqrt                             10   \n",
      "26                              sqrt                             10   \n",
      "27                              sqrt                             10   \n",
      "28                              log2                             10   \n",
      "29                              log2                             10   \n",
      "30                              log2                             10   \n",
      "31                              log2                             10   \n",
      "32                              None                             10   \n",
      "33                              None                             10   \n",
      "34                              None                             10   \n",
      "35                              None                             10   \n",
      "36                              sqrt                           None   \n",
      "37                              sqrt                           None   \n",
      "38                              sqrt                           None   \n",
      "39                              sqrt                           None   \n",
      "40                              log2                           None   \n",
      "41                              log2                           None   \n",
      "42                              log2                           None   \n",
      "43                              log2                           None   \n",
      "44                              None                           None   \n",
      "45                              None                           None   \n",
      "46                              None                           None   \n",
      "47                              None                           None   \n",
      "\n",
      "   param_decision_tree__min_samples_leaf  mean_test_score  \n",
      "0                                      1         0.573248  \n",
      "1                                      3         0.573248  \n",
      "2                                      5         0.573248  \n",
      "3                                     10         0.573248  \n",
      "4                                      1         0.503296  \n",
      "5                                      3         0.503296  \n",
      "6                                      5         0.503296  \n",
      "7                                     10         0.503296  \n",
      "8                                      1         0.621485  \n",
      "9                                      3         0.621485  \n",
      "10                                     5         0.621485  \n",
      "11                                    10         0.621485  \n",
      "12                                     1         0.583330  \n",
      "13                                     3         0.583329  \n",
      "14                                     5         0.583330  \n",
      "15                                    10         0.583330  \n",
      "16                                     1         0.506678  \n",
      "17                                     3         0.506671  \n",
      "18                                     5         0.506672  \n",
      "19                                    10         0.506671  \n",
      "20                                     1         0.631875  \n",
      "21                                     3         0.631875  \n",
      "22                                     5         0.631875  \n",
      "23                                    10         0.631875  \n",
      "24                                     1         0.601990  \n",
      "25                                     3         0.602716  \n",
      "26                                     5         0.607654  \n",
      "27                                    10         0.594804  \n",
      "28                                     1         0.512148  \n",
      "29                                     3         0.512231  \n",
      "30                                     5         0.512486  \n",
      "31                                    10         0.512306  \n",
      "32                                     1         0.646803  \n",
      "33                                     3         0.646792  \n",
      "34                                     5         0.646820  \n",
      "35                                    10         0.646870  \n",
      "36                                     1         0.597343  \n",
      "37                                     3         0.626045  \n",
      "38                                     5         0.634018  \n",
      "39                                    10         0.639746  \n",
      "40                                     1         0.580045  \n",
      "41                                     3         0.614233  \n",
      "42                                     5         0.617712  \n",
      "43                                    10         0.617297  \n",
      "44                                     1         0.616649  \n",
      "45                                     3         0.615557  \n",
      "46                                     5         0.622533  \n",
      "47                                    10         0.636903  \n"
     ]
    }
   ],
   "source": [
    "print(\"Max Features = {bestccp}, Max Depth = {bestMD}, Min Samples Leaf = {bestMS}, with an accuracy of {bestScore}.\\n\".format(\n",
    "    bestccp = dtc_grid_result.best_params_['decision_tree__ccp_alpha'],\n",
    "    bestMD = dtc_grid_result.best_params_['decision_tree__max_depth'],\n",
    "    bestMS = dtc_grid_result.best_params_['decision_tree__min_samples_leaf'],\n",
    "    bestScore = dtc_grid_result.best_score_))\n",
    "\n",
    "res = pd.DataFrame(dtc_grid_result.cv_results_)\n",
    "print(res[['param_decision_tree__max_features',\n",
    "           'param_decision_tree__max_depth',\n",
    "           'param_decision_tree__min_samples_leaf',\n",
    "           'mean_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pipe.set_params(decision_tree__max_features = None, decision_tree__max_depth = 10, decision_tree__min_samples_leaf = 10)\n",
    "\n",
    "dtc = fitmodel(model = dtc_pipe,\n",
    "               filename = \"models/decision_tree.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predictors = list(set(game_train.head()).difference({\"p1_won\",\"p1_id\",\"p2_id\"}))\n",
    "\n",
    "rfc_pipe = Pipeline(steps = [\n",
    "            (\"predictors\", ColumnTransformer([(\"predictors\",\"passthrough\",rfc_predictors)])),\n",
    "            (\"random_forest\", ensemble.RandomForestClassifier(verbose = 3, n_jobs = 4, random_state = 420))\n",
    "            ])\n",
    "\n",
    "rfc_grid = dict(random_forest__n_estimators = [50,100,150,200],\n",
    "                random_forest__max_features = [\"sqrt\",\"log2\"],\n",
    "                random_forest__min_samples_leaf = [1, 3, 5, 10])\n",
    "\n",
    "game_folded = StratifiedKFold(n_splits=5).split(X,y)\n",
    "\n",
    "rfc_grid_search = GridSearchCV(estimator = rfc_pipe,\n",
    "                               param_grid = rfc_grid,\n",
    "                               n_jobs = 1,\n",
    "                               cv = game_folded,\n",
    "                               scoring = 'accuracy',\n",
    "                               error_score = 0,\n",
    "                               verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5; 1/32] START random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/32] END random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__n_estimators=50;, score=0.663 total time= 4.1min\n",
      "[CV 2/5; 1/32] START random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/32] END random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__n_estimators=50;, score=0.665 total time= 4.1min\n",
      "[CV 3/5; 1/32] START random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/32] END random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__n_estimators=50;, score=0.664 total time= 4.1min\n",
      "[CV 4/5; 1/32] START random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rfc_grid_results \u001b[39m=\u001b[39m rfc_grid_search\u001b[39m.\u001b[39;49mfit(X,y)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 440\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Colton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rfc_grid_results = rfc_grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max Features = {bestn}, Max Depth = {bestMF}, Min Samples Leaf = {bestMS}, with an accuracy of {bestScore}.\\n\".format(\n",
    "    bestn = dtc_grid_result.best_params_['random_forest__n_estimators'],\n",
    "    bestMF = dtc_grid_result.best_params_['random_forest__max_features'],\n",
    "    bestMS = dtc_grid_result.best_params_['random_forest__min_samples_leaf'],\n",
    "    bestScore = dtc_grid_result.best_score_))\n",
    "\n",
    "res = pd.DataFrame(dtc_grid_result.cv_results_)\n",
    "print(res[['param_random_forest__n_estimators',\n",
    "           'param_random_forest__max_features',\n",
    "           'param_random_forest__min_samples_leaf',\n",
    "           'mean_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3699          173.08m\n",
      "         2           1.3559          167.11m\n",
      "         3           1.3441          163.77m\n",
      "         4           1.3339          162.37m\n",
      "         5           1.3253          161.80m\n",
      "         6           1.3177          160.94m\n",
      "         7           1.3114          160.17m\n",
      "         8           1.3059          159.88m\n",
      "         9           1.3011          159.59m\n",
      "        10           1.2968          159.46m\n",
      "        11           1.2930          159.16m\n",
      "        12           1.2897          159.60m\n",
      "        13           1.2869          159.73m\n",
      "        14           1.2842          159.98m\n",
      "        15           1.2820          159.91m\n",
      "        16           1.2798          159.95m\n",
      "        17           1.2780          159.86m\n",
      "        18           1.2761          159.32m\n",
      "        19           1.2746          158.91m\n",
      "        20           1.2732          158.32m\n",
      "        21           1.2719          158.10m\n",
      "        22           1.2706          157.58m\n",
      "        23           1.2696          157.21m\n",
      "        24           1.2685          156.72m\n",
      "        25           1.2675          156.13m\n",
      "        26           1.2664          155.78m\n",
      "        27           1.2655          155.30m\n",
      "        28           1.2646          155.03m\n",
      "        29           1.2637          154.56m\n",
      "        30           1.2631          154.31m\n",
      "        31           1.2622          153.92m\n",
      "        32           1.2613          153.54m\n",
      "        33           1.2608          153.21m\n",
      "        34           1.2600          152.96m\n",
      "        35           1.2593          152.62m\n",
      "        36           1.2587          152.34m\n",
      "        37           1.2579          152.06m\n",
      "        38           1.2574          151.70m\n",
      "        39           1.2570          151.42m\n",
      "        40           1.2563          151.19m\n",
      "        41           1.2557          150.85m\n",
      "        42           1.2550          150.64m\n",
      "        43           1.2545          150.38m\n",
      "        44           1.2542          149.99m\n",
      "        45           1.2535          149.82m\n",
      "        46           1.2529          149.59m\n",
      "        47           1.2526          149.22m\n",
      "        48           1.2521          148.98m\n",
      "        49           1.2514          148.75m\n",
      "        50           1.2508          148.55m\n",
      "        51           1.2506          148.18m\n",
      "        52           1.2501          147.91m\n",
      "        53           1.2498          147.59m\n",
      "        54           1.2493          147.29m\n",
      "        55           1.2489          147.08m\n",
      "        56           1.2488          146.77m\n",
      "        57           1.2482          146.74m\n",
      "        58           1.2477          146.41m\n",
      "        59           1.2475          146.02m\n",
      "        60           1.2470          145.70m\n",
      "        61           1.2465          145.38m\n",
      "        62           1.2462          145.09m\n",
      "        63           1.2459          144.77m\n",
      "        64           1.2458          144.41m\n",
      "        65           1.2453          144.13m\n",
      "        66           1.2452          143.77m\n",
      "        67           1.2451          143.41m\n",
      "        68           1.2446          143.22m\n",
      "        69           1.2444          142.90m\n",
      "        70           1.2443          142.56m\n",
      "        71           1.2437          142.32m\n",
      "        72           1.2435          142.03m\n",
      "        73           1.2434          141.70m\n",
      "        74           1.2433          141.40m\n",
      "        75           1.2428          141.19m\n",
      "        76           1.2422          141.00m\n",
      "        77           1.2421          140.69m\n",
      "        78           1.2419          140.40m\n",
      "        79           1.2417          140.14m\n",
      "        80           1.2416          139.83m\n",
      "        81           1.2410          139.64m\n",
      "        82           1.2403          139.45m\n",
      "        83           1.2400          139.26m\n",
      "        84           1.2399          138.97m\n",
      "        85           1.2397          138.73m\n",
      "        86           1.2396          138.46m\n",
      "        87           1.2390          138.28m\n",
      "        88           1.2389          138.00m\n",
      "        89           1.2385          137.77m\n",
      "        90           1.2379          137.61m\n",
      "        91           1.2374          137.45m\n",
      "        92           1.2373          137.19m\n",
      "        93           1.2370          136.95m\n",
      "        94           1.2365          136.78m\n",
      "        95           1.2364          136.50m\n",
      "        96           1.2361          136.31m\n",
      "        97           1.2357          136.09m\n",
      "        98           1.2354          135.88m\n",
      "        99           1.2351          135.71m\n",
      "       100           1.2346          135.54m\n",
      "       101           1.2343          135.32m\n",
      "       102           1.2343          135.07m\n",
      "       103           1.2342          134.83m\n",
      "       104           1.2337          134.68m\n",
      "       105           1.2332          134.55m\n",
      "       106           1.2329          134.33m\n",
      "       107           1.2328          134.09m\n",
      "       108           1.2327          133.85m\n",
      "       109           1.2326          133.62m\n",
      "       110           1.2325          133.39m\n",
      "       111           1.2325          133.17m\n",
      "       112           1.2324          132.93m\n",
      "       113           1.2320          132.79m\n",
      "       114           1.2318          132.57m\n",
      "       115           1.2318          132.33m\n",
      "       116           1.2314          132.16m\n",
      "       117           1.2309          132.00m\n",
      "       118           1.2309          131.78m\n",
      "       119           1.2308          131.55m\n",
      "       120           1.2308          131.34m\n",
      "       121           1.2303          131.19m\n",
      "       122           1.2303          130.96m\n",
      "       123           1.2300          130.77m\n",
      "       124           1.2294          130.65m\n",
      "       125           1.2293          130.45m\n",
      "       126           1.2292          130.23m\n",
      "       127           1.2287          130.08m\n",
      "       128           1.2282          129.92m\n",
      "       129           1.2282          129.70m\n",
      "       130           1.2279          129.52m\n",
      "       131           1.2278          129.31m\n",
      "       132           1.2278          129.09m\n",
      "       133           1.2277          128.88m\n",
      "       134           1.2274          128.70m\n",
      "       135           1.2274          128.49m\n",
      "       136           1.2269          128.36m\n",
      "       137           1.2264          128.22m\n",
      "       138           1.2263          128.01m\n",
      "       139           1.2263          127.79m\n",
      "       140           1.2258          127.66m\n",
      "       141           1.2257          127.44m\n",
      "       142           1.2257          127.25m\n",
      "       143           1.2256          127.06m\n",
      "       144           1.2253          126.89m\n",
      "       145           1.2249          126.75m\n",
      "       146           1.2245          126.60m\n",
      "       147           1.2242          126.43m\n",
      "       148           1.2239          126.26m\n",
      "       149           1.2236          126.12m\n",
      "       150           1.2232          125.98m\n",
      "       151           1.2231          125.78m\n",
      "       152           1.2230          125.58m\n",
      "       153           1.2227          125.41m\n",
      "       154           1.2227          125.21m\n",
      "       155           1.2227          125.01m\n",
      "       156           1.2223          124.84m\n",
      "       157           1.2223          124.65m\n",
      "       158           1.2219          124.52m\n",
      "       159           1.2217          124.36m\n",
      "       160           1.2216          124.17m\n",
      "       161           1.2215          123.97m\n",
      "       162           1.2212          123.81m\n",
      "       163           1.2208          123.66m\n",
      "       164           1.2208          123.47m\n",
      "       165           1.2206          123.29m\n",
      "       166           1.2202          123.15m\n",
      "       167           1.2200          122.98m\n",
      "       168           1.2198          122.81m\n",
      "       169           1.2194          122.68m\n",
      "       170           1.2194          122.50m\n",
      "       171           1.2193          122.31m\n",
      "       172           1.2191          122.15m\n",
      "       173           1.2187          122.02m\n",
      "       174           1.2186          121.83m\n",
      "       175           1.2184          121.66m\n",
      "       176           1.2180          121.56m\n",
      "       177           1.2177          121.43m\n",
      "       178           1.2176          121.24m\n",
      "       179           1.2174          121.06m\n",
      "       180           1.2174          120.87m\n",
      "       181           1.2170          120.73m\n",
      "       182           1.2169          120.54m\n",
      "       183           1.2169          120.36m\n",
      "       184           1.2166          120.20m\n",
      "       185           1.2163          120.05m\n",
      "       186           1.2162          119.87m\n",
      "       187           1.2159          119.71m\n",
      "       188           1.2158          119.53m\n",
      "       189           1.2155          119.38m\n",
      "       190           1.2155          119.20m\n",
      "       191           1.2154          119.01m\n",
      "       192           1.2152          118.85m\n",
      "       193           1.2149          118.72m\n",
      "       194           1.2147          118.56m\n",
      "       195           1.2145          118.42m\n",
      "       196           1.2144          118.24m\n",
      "       197           1.2144          118.06m\n",
      "       198           1.2142          117.88m\n",
      "       199           1.2142          117.70m\n",
      "       200           1.2139          117.57m\n",
      "       201           1.2135          117.43m\n",
      "       202           1.2132          117.29m\n",
      "       203           1.2130          117.13m\n",
      "       204           1.2130          116.95m\n",
      "       205           1.2129          116.77m\n",
      "       206           1.2129          116.59m\n",
      "       207           1.2128          116.42m\n",
      "       208           1.2128          116.25m\n",
      "       209           1.2126          116.09m\n",
      "       210           1.2125          115.92m\n",
      "       211           1.2121          115.79m\n",
      "       212           1.2120          115.62m\n",
      "       213           1.2118          115.46m\n",
      "       214           1.2116          115.30m\n",
      "       215           1.2113          115.16m\n",
      "       216           1.2110          115.03m\n",
      "       217           1.2107          114.88m\n",
      "       218           1.2103          114.74m\n",
      "       219           1.2100          114.60m\n",
      "       220           1.2098          114.46m\n",
      "       221           1.2095          114.32m\n",
      "       222           1.2092          114.19m\n",
      "       223           1.2089          114.05m\n",
      "       224           1.2089          113.88m\n",
      "       225           1.2088          113.71m\n",
      "       226           1.2086          113.57m\n",
      "       227           1.2085          113.40m\n",
      "       228           1.2083          113.25m\n",
      "       229           1.2081          113.10m\n",
      "       230           1.2078          112.96m\n",
      "       231           1.2077          112.79m\n",
      "       232           1.2076          112.63m\n",
      "       233           1.2074          112.47m\n",
      "       234           1.2072          112.33m\n",
      "       235           1.2071          112.16m\n",
      "       236           1.2071          111.98m\n",
      "       237           1.2070          111.81m\n",
      "       238           1.2070          111.64m\n",
      "       239           1.2070          111.47m\n",
      "       240           1.2067          111.33m\n",
      "       241           1.2065          111.17m\n",
      "       242           1.2062          111.04m\n",
      "       243           1.2062          110.87m\n",
      "       244           1.2060          110.73m\n",
      "       245           1.2058          110.59m\n",
      "       246           1.2057          110.43m\n",
      "       247           1.2057          110.28m\n",
      "       248           1.2056          110.13m\n",
      "       249           1.2053          109.99m\n",
      "       250           1.2050          109.85m\n",
      "       251           1.2047          109.71m\n",
      "       252           1.2047          109.55m\n",
      "       253           1.2046          109.40m\n",
      "       254           1.2043          109.29m\n",
      "       255           1.2040          109.16m\n",
      "       256           1.2038          109.02m\n",
      "       257           1.2036          108.89m\n",
      "       258           1.2035          108.73m\n",
      "       259           1.2033          108.59m\n",
      "       260           1.2031          108.45m\n",
      "       261           1.2031          108.28m\n",
      "       262           1.2030          108.11m\n",
      "       263           1.2030          107.94m\n",
      "       264           1.2030          107.77m\n",
      "       265           1.2029          107.60m\n",
      "       266           1.2029          107.43m\n",
      "       267           1.2029          107.26m\n",
      "       268           1.2026          107.13m\n",
      "       269           1.2024          107.00m\n",
      "       270           1.2022          106.87m\n",
      "       271           1.2020          106.72m\n",
      "       272           1.2018          106.58m\n",
      "       273           1.2017          106.43m\n",
      "       274           1.2015          106.28m\n",
      "       275           1.2013          106.14m\n",
      "       276           1.2013          105.98m\n",
      "       277           1.2011          105.84m\n",
      "       278           1.2009          105.71m\n",
      "       279           1.2007          105.58m\n",
      "       280           1.2006          105.42m\n",
      "       281           1.2005          105.25m\n",
      "       282           1.2003          105.12m\n",
      "       283           1.2001          104.98m\n",
      "       284           1.1999          104.84m\n",
      "       285           1.1997          104.71m\n",
      "       286           1.1995          104.57m\n",
      "       287           1.1993          104.43m\n",
      "       288           1.1991          104.30m\n",
      "       289           1.1990          104.15m\n",
      "       290           1.1989          104.00m\n",
      "       291           1.1988          103.84m\n",
      "       292           1.1988          103.68m\n",
      "       293           1.1986          103.52m\n",
      "       294           1.1984          103.38m\n",
      "       295           1.1983          103.25m\n",
      "       296           1.1982          103.08m\n",
      "       297           1.1980          102.94m\n",
      "       298           1.1980          102.79m\n",
      "       299           1.1979          102.66m\n",
      "       300           1.1978          102.51m\n",
      "       301           1.1977          102.35m\n",
      "       302           1.1977          102.20m\n",
      "       303           1.1977          102.04m\n",
      "       304           1.1975          101.91m\n",
      "       305           1.1973          101.78m\n",
      "       306           1.1972          101.63m\n"
     ]
    }
   ],
   "source": [
    "gbc = None\n",
    "gbcfile = \"models/boosted_tree.joblib\"\n",
    "\n",
    "predictors = list(set(game_train.head()).difference({\"p1_won\",\"p1_id\",\"p2_id\"}))\n",
    "response = \"p1_won\"\n",
    "\n",
    "if not os.path.isfile(gbcfile):\n",
    "    gbc = ensemble.GradientBoostingClassifier(verbose=3,n_estimators=1000)\n",
    "\n",
    "    x = game_train[predictors]\n",
    "    y = game_train[response]\n",
    "\n",
    "    gbc.fit(x,y)\n",
    "\n",
    "    joblib.dump(gbc,gbcfile)\n",
    "else:\n",
    "    gbc = joblib.load(gbcfile)\n",
    "\n",
    "prediction = gbc.predict(game_train[gbc.feature_names_in_])\n",
    "actual = game_train[response]\n",
    "\n",
    "print(\"Accuracy: {acc}\".format(acc = accuracy_score(prediction,actual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6854507297915556\n"
     ]
    }
   ],
   "source": [
    "prediction = gbc.predict(game_test[gbc.feature_names_in_])\n",
    "actual = game_test[response]\n",
    "\n",
    "print(\"Accuracy: {acc}\".format(acc = accuracy_score(prediction,actual)))\n",
    "# CROSS VALIDATION FIRST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
